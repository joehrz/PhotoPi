{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import networkx as nx\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafAngleAnalyzer:\n",
    "    \"\"\"\n",
    "    LeafAngleAnalyzer computes leaf angles from segmented plant point cloud data.\n",
    "\n",
    "    It expects that the segmentation instance (from MainStemSegmentation) \n",
    "    has already identified branch 'stem' vs. 'leaf' points for each branch, \n",
    "    typically stored as:\n",
    "      - all_main_stem_points_up[i]: Nx3 array (the 'up' portion of the main stem)\n",
    "      - all_main_stem_points_down[i]: Nx3 array (the 'down' portion of the main stem)\n",
    "      - all_leaf_points[i]: Nx3 array of leaf region points\n",
    "\n",
    "    This class can then:\n",
    "      - Compute leaf angles by performing a linear regression on (z vs. x,y) \n",
    "        for the main stem and the leaf.\n",
    "      - Visualize these angles in Open3D by drawing arcs and lines.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    segmentation : MainStemSegmentation (or similar)\n",
    "        An instance that holds references to 'all_main_stem_points_up', \n",
    "        'all_main_stem_points_down', and 'all_leaf_points'.\n",
    "    angles : list of float or None\n",
    "        Computed leaf angles (in degrees) for each branch. If a branch \n",
    "        does not meet the minimum data requirement, its angle is None.\n",
    "    main_leaf_angle : float or None\n",
    "        An optional metric for the \"main leaf angle\" (e.g., topmost leaf).\n",
    "    main_leaf_branch_index : int or None\n",
    "        Which branch index had the \"main leaf angle\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segmentation):\n",
    "        \"\"\"\n",
    "        Initialize with a segmentation object that has \n",
    "        main-stem and leaf points for each branch region.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        segmentation : object\n",
    "            Should contain:\n",
    "              segmentation.all_main_stem_points_up\n",
    "              segmentation.all_main_stem_points_down\n",
    "              segmentation.all_leaf_points\n",
    "            each a list of Nx3 arrays.\n",
    "        \"\"\"\n",
    "        self.segmentation = segmentation\n",
    "        self.angles = []  # Computed leaf angles per branch\n",
    "        self.main_leaf_angle = None\n",
    "        self.main_leaf_branch_index = None\n",
    "\n",
    "\n",
    "    def compute_leaf_angles_node_bfs(\n",
    "            self,\n",
    "            n_main_stem=5,\n",
    "            n_leaf=5,\n",
    "            min_leaf_for_angle=4,\n",
    "            max_bfs_depth=5\n",
    "        ):\n",
    "        \"\"\"\n",
    "        For each branch_off node, gather nearby stem & leaf points by BFS,\n",
    "        fit regression lines via SVD, and compute the full 0–180° angle\n",
    "        between them.\n",
    "        \"\"\"\n",
    "        G         = self.segmentation.G_neg_final\n",
    "        cpoints   = self.segmentation.cpoints_final\n",
    "        trunk_ids = self.segmentation.trunk_path\n",
    "        b_offs    = self.segmentation.branch_off_nodes\n",
    "\n",
    "        if G is None or cpoints is None or not trunk_ids:\n",
    "            print(\"[ERROR] Segmentation data missing or invalid.\")\n",
    "            return []\n",
    "\n",
    "        def undirected_neighbors(u):\n",
    "            return set(G.successors(u)) | set(G.predecessors(u))\n",
    "\n",
    "        def count_leaf_nodes_bfs(start, depth_limit):\n",
    "            visited, queue, leaf_cnt = set(), deque([(start,0)]), 0\n",
    "            while queue:\n",
    "                nd, dpt = queue.popleft()\n",
    "                if nd in visited:\n",
    "                    continue\n",
    "                visited.add(nd)\n",
    "                if G.nodes[nd].get('type')=='leaf':\n",
    "                    leaf_cnt += 1\n",
    "                if dpt < depth_limit:\n",
    "                    for nb in undirected_neighbors(nd):\n",
    "                        if nb not in visited:\n",
    "                            queue.append((nb, dpt+1))\n",
    "            return leaf_cnt\n",
    "\n",
    "        def collect_leaf_nodes_bfs(start, n_leaf):\n",
    "            visited, queue, leaves = set(), deque(), []\n",
    "            for nb in undirected_neighbors(start):\n",
    "                if G.nodes[nb].get('type')=='leaf':\n",
    "                    queue.append(nb)\n",
    "            while queue and len(leaves) < n_leaf:\n",
    "                curr = queue.popleft()\n",
    "                if curr in visited:\n",
    "                    continue\n",
    "                visited.add(curr)\n",
    "                if G.nodes[curr].get('type')=='leaf':\n",
    "                    leaves.append(curr)\n",
    "                    for nxt in undirected_neighbors(curr):\n",
    "                        if nxt not in visited and G.nodes[nxt].get('type')=='leaf':\n",
    "                            queue.append(nxt)\n",
    "            return leaves\n",
    "\n",
    "        def fit_line_svd(pts):\n",
    "            arr = np.asarray(pts)\n",
    "            if arr.shape[0] < 2:\n",
    "                return (None, None)\n",
    "            center = arr.mean(axis=0)\n",
    "            uu, ss, vh = np.linalg.svd(arr - center)\n",
    "            direction = vh[0] / np.linalg.norm(vh[0])\n",
    "            return center, direction\n",
    "\n",
    "        self.branch_data = []\n",
    "        trunk_set = set(trunk_ids)\n",
    "\n",
    "        for b_off in b_offs:\n",
    "            if b_off not in trunk_set:\n",
    "                continue\n",
    "\n",
    "            leaf_count = count_leaf_nodes_bfs(b_off, max_bfs_depth)\n",
    "            if leaf_count < min_leaf_for_angle:\n",
    "                continue\n",
    "\n",
    "            idx        = trunk_ids.index(b_off)\n",
    "            aboveIDs   = trunk_ids[idx+1 : idx+1+n_main_stem]\n",
    "            belowIDs   = trunk_ids[max(0, idx-n_main_stem) : idx]\n",
    "            trunk_nodes = aboveIDs + belowIDs\n",
    "            trunk_points = [cpoints[tn] for tn in trunk_nodes if tn < len(cpoints)]\n",
    "            if len(trunk_points) < 2:\n",
    "                continue\n",
    "\n",
    "            leaf_nodes  = collect_leaf_nodes_bfs(b_off, n_leaf)\n",
    "            leaf_points = [cpoints[ln] for ln in leaf_nodes if ln < len(cpoints)]\n",
    "            if len(leaf_points) < 2:\n",
    "                continue\n",
    "\n",
    "            stem_center, stem_dir = fit_line_svd(trunk_points)\n",
    "            leaf_center, leaf_dir = fit_line_svd(leaf_points)\n",
    "            if stem_dir is None or leaf_dir is None:\n",
    "                continue\n",
    "\n",
    "            # Full 0–180° angle, no flipping\n",
    "            dot_val   = np.clip(np.dot(stem_dir, leaf_dir), -1.0, 1.0)\n",
    "            angle_deg = np.degrees(np.arccos(dot_val))\n",
    "\n",
    "            z_position = float(cpoints[b_off][2]) if b_off < len(cpoints) else float('-inf')\n",
    "\n",
    "            self.branch_data.append({\n",
    "                'branch_off':    b_off,\n",
    "                'stem_points':   np.array(trunk_points),\n",
    "                'leaf_points':   np.array(leaf_points),\n",
    "                'angle_degrees': angle_deg,\n",
    "                'z_position':    z_position\n",
    "            })\n",
    "            print(f\"[NODE-BFS ANGLE] b_off={b_off}, angle={angle_deg:.2f}°, z={z_position:.2f}\")\n",
    "\n",
    "        self.angles = [bd['angle_degrees'] for bd in self.branch_data]\n",
    "\n",
    "        # pick main leaf by highest z\n",
    "        best_idx, highest_z = None, float('-inf')\n",
    "        for i, bd in enumerate(self.branch_data):\n",
    "            z_pos = bd['z_position']\n",
    "            if z_pos > highest_z:\n",
    "                highest_z, best_idx = z_pos, i\n",
    "\n",
    "        if best_idx is not None:\n",
    "            self.main_leaf_angle = self.branch_data[best_idx]['angle_degrees']\n",
    "            self.main_leaf_branch_index = best_idx\n",
    "            print(f\"[MAIN ANGLE] branch={best_idx}, angle={self.main_leaf_angle:.2f}°, z={highest_z:.2f}\")\n",
    "        else:\n",
    "            self.main_leaf_angle = None\n",
    "            self.main_leaf_branch_index = None\n",
    "            print(\"[WARN] No main leaf angle found.\")\n",
    "\n",
    "        return self.branch_data\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # (Optional) If you want to visualize BFS-based angles\n",
    "    # in Open3D, you can add a method similar to the old code\n",
    "    # but now you have the BFS-based trunk_points/leaf_points\n",
    "    # in self.branch_data. For example:\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def visualize_bfs_leaf_angles_open3d(self):\n",
    "        \"\"\"\n",
    "        Example visualization that draws:\n",
    "         - trunk_points in red\n",
    "         - leaf_points in green\n",
    "         - a line for trunk, a line for leaf\n",
    "         - an arc representing the angle\n",
    "\n",
    "        BFS-based approach: we pull data from self.branch_data, where\n",
    "        trunk_points & leaf_points were found by BFS.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        geoms = []\n",
    "        for i, bd in enumerate(self.branch_data):\n",
    "            trunk_pts = bd['stem_points']\n",
    "            leaf_pts  = bd['leaf_points']\n",
    "            angle_deg = bd['angle_degrees']\n",
    "\n",
    "            # Build small point clouds\n",
    "            trunk_pcd = o3d.geometry.PointCloud()\n",
    "            trunk_pcd.points = o3d.utility.Vector3dVector(trunk_pts)\n",
    "            trunk_pcd.paint_uniform_color([1,0,0])  # red\n",
    "            geoms.append(trunk_pcd)\n",
    "\n",
    "            leaf_pcd  = o3d.geometry.PointCloud()\n",
    "            leaf_pcd.points = o3d.utility.Vector3dVector(leaf_pts)\n",
    "            leaf_pcd.paint_uniform_color([0,1,0])  # green\n",
    "            geoms.append(leaf_pcd)\n",
    "\n",
    "            # Lines for trunk, leaf (just 2 endpoints if you want)\n",
    "            # Or do an SVD-based line for each\n",
    "            # We'll do a minimal approach => just from minZ to maxZ\n",
    "            # or re-use the 'fit_line_svd' function.\n",
    "            # ...\n",
    "            # For brevity, we won't show the entire line or arc code here:\n",
    "            print(f\"Branch {i} => angle= {angle_deg:.2f} deg\")\n",
    "\n",
    "        # show them\n",
    "        if geoms:\n",
    "            o3d.visualization.draw_geometries(geoms, window_name=\"BFS Leaf Angles\")\n",
    "        else:\n",
    "            print(\"[WARN] No BFS angles to visualize or empty branch_data.\")\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # Visualization of Leaf Angles in Open3D\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    def visualize_leaf_angles(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Display in Open3D each branch’s trunk/leaf lines plus an arc\n",
    "        representing the BFS-based angle between them. Adds a small sphere at\n",
    "        the midpoint of the arc for better visual reference.\n",
    "        Points and lines are displayed larger for improved readability.\n",
    "        \"\"\"\n",
    "        geoms = []\n",
    "        for i, bd in enumerate(self.branch_data):\n",
    "            trunk_pts = bd['stem_points']\n",
    "            leaf_pts  = bd['leaf_points']\n",
    "            angle_deg = bd.get('angle_degrees', None)\n",
    "\n",
    "            if trunk_pts.shape[0] < 2 or leaf_pts.shape[0] < 2:\n",
    "                print(f\"[WARN] branch {i} => not enough trunk/leaf points => skipping.\")\n",
    "                continue\n",
    "\n",
    "            # (A) Create point clouds for raw BFS-based data.\n",
    "            geoms += self._pcd_from_points(trunk_pts, color=[1, 0, 0])  # red for stem\n",
    "            geoms += self._pcd_from_points(leaf_pts,  color=[0, 1, 0])  # green for leaf\n",
    "\n",
    "            # (B) Fit lines in 3D using SVD => sample Nx3 line.\n",
    "            trunk_reg_pts = self._fit_line_svd_as_points(trunk_pts, n_samples=30)\n",
    "            leaf_reg_pts  = self._fit_line_svd_as_points(leaf_pts,  n_samples=30)\n",
    "\n",
    "            # (C) Create line sets for trunk & leaf \"regression lines\".\n",
    "            geoms += self._lineset_from_points(trunk_reg_pts, color=[0, 0, 1])   # blue line\n",
    "            geoms += self._lineset_from_points(leaf_reg_pts,  color=[1, 0, 1])   # magenta line\n",
    "\n",
    "            # (D) Add the arc and sphere at midpoint.\n",
    "            if trunk_reg_pts.shape[0] >= 2 and leaf_reg_pts.shape[0] >= 2:\n",
    "                arc_geoms = self._arc_for_angle(\n",
    "                    trunk_reg_pts[0],\n",
    "                    trunk_reg_pts[-1],\n",
    "                    leaf_reg_pts[-1]\n",
    "                )\n",
    "                geoms.extend(arc_geoms)\n",
    "\n",
    "            # Print the BFS-based angle.\n",
    "            if angle_deg is not None:\n",
    "                print(f\"[INFO] branch {i} => BFS-based angle= {angle_deg:.2f} deg\")\n",
    "            else:\n",
    "                print(f\"[INFO] branch {i} => BFS-based angle= ??? (not in branch_data)\")\n",
    "\n",
    "        if not geoms:\n",
    "            print(\"[WARN] no geometry => no BFS angles to display.\")\n",
    "            return\n",
    "\n",
    "        # Use the Visualizer to adjust render options for better readability.\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window(window_name=\"BFS Leaf Angles w/ Arc Spheres\")\n",
    "        for geom in geoms:\n",
    "            vis.add_geometry(geom)\n",
    "        \n",
    "        # Increase point size and line width.\n",
    "        opt = vis.get_render_option()\n",
    "        opt.point_size = 10.0   # Increase point size (adjust as desired)\n",
    "        opt.line_width = 3.0    # Increase line width (adjust as desired)\n",
    "        \n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # Helpers for geometry creation and line fitting\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    def _pcd_from_points(self, points, color=[1,0,0]):\n",
    "        \"\"\"\n",
    "        Helper: create a small geometry list with a single PointCloud of 'points'.\n",
    "        \"\"\"\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.paint_uniform_color(color)\n",
    "        return [pcd]\n",
    "\n",
    "    def _lineset_from_points(self, pts, color=[0,0,1]):\n",
    "        \"\"\"\n",
    "        Given Nx3 points (like a 'regression line'), build a line set in a single color.\n",
    "        \"\"\"\n",
    "        if len(pts) < 2:\n",
    "            return []\n",
    "        lines = [[i, i+1] for i in range(len(pts)-1)]\n",
    "        ls = o3d.geometry.LineSet()\n",
    "        ls.points = o3d.utility.Vector3dVector(pts)\n",
    "        ls.lines  = o3d.utility.Vector2iVector(lines)\n",
    "        ls.colors = o3d.utility.Vector3dVector([color]*len(lines))\n",
    "        return [ls]\n",
    "\n",
    "    def _fit_line_svd_as_points(self, pts, n_samples=30):\n",
    "        \"\"\"\n",
    "        Similar to 'regression' but in 3D with SVD:\n",
    "          - Fit principal axis for 'pts'\n",
    "          - Create line from min_proj..max_proj at intervals => Nx3 array\n",
    "\n",
    "        Returns Nx3 array of sampled points along the best-fit line.\n",
    "        \"\"\"\n",
    "        arr = np.asarray(pts)\n",
    "        center = arr.mean(axis=0)\n",
    "        if arr.shape[0] < 2:\n",
    "            return arr  # degenerate\n",
    "\n",
    "        # SVD => first principal component\n",
    "        uu, ss, vh = np.linalg.svd(arr - center)\n",
    "        direction  = vh[0] / np.linalg.norm(vh[0])  # principal axis\n",
    "\n",
    "        # Project all points onto that axis => find min/max\n",
    "        projs = np.dot((arr - center), direction)  # shape (N,)\n",
    "        min_t, max_t = np.min(projs), np.max(projs)\n",
    "\n",
    "        # Sample n_samples points from min_t..max_t\n",
    "        ts = np.linspace(min_t, max_t, n_samples)\n",
    "        line_pts = [center + t*direction for t in ts]\n",
    "        return np.array(line_pts)\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # Arc creation + a sphere at its midpoint\n",
    "    # --------------------------------------------------------------------\n",
    "\n",
    "    def _arc_for_angle(self, stem_start, stem_end, leaf_end):\n",
    "        \"\"\"\n",
    "        Creates:\n",
    "          1) A LineSet for the arc from (stem_start->stem_end) to (stem_start->leaf_end)\n",
    "          2) A small sphere at the midpoint of that arc\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        geoms : list of open3d.geometry.Geometry\n",
    "            [arc_lineset, sphere_at_mid]\n",
    "        \"\"\"\n",
    "        arc_pts = self._create_arc_points(stem_start, stem_end, leaf_end, num_points=30)\n",
    "        if arc_pts.shape[0] < 2:\n",
    "            return []  # no arc\n",
    "\n",
    "        # (1) build a lineset for the arc\n",
    "        arc_lines = [[i, i+1] for i in range(len(arc_pts)-1)]\n",
    "        arc_ls = o3d.geometry.LineSet()\n",
    "        arc_ls.points = o3d.utility.Vector3dVector(arc_pts)\n",
    "        arc_ls.lines  = o3d.utility.Vector2iVector(arc_lines)\n",
    "        arc_ls.colors = o3d.utility.Vector3dVector([[0,0,0]]* len(arc_lines))  # yellow\n",
    "\n",
    "        # (2) small sphere at midpoint\n",
    "        mid_idx = len(arc_pts)//2\n",
    "        mid_pt  = arc_pts[mid_idx]\n",
    "        sphere  = self._create_sphere_at_point(mid_pt, radius=0.002, color=[0,0,0])\n",
    "\n",
    "        return [arc_ls, sphere]\n",
    "\n",
    "    def _create_arc_points(self, center, end1, end2, num_points=30):\n",
    "        \"\"\"\n",
    "        Create a set of 3D arc points from the vectors (center->end1) to (center->end2).\n",
    "        \"\"\"\n",
    "        v1 = end1 - center\n",
    "        v2 = end2 - center\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "        if norm1<1e-9 or norm2<1e-9:\n",
    "            return np.vstack([center, end1, end2])  # degenerate\n",
    "\n",
    "        v1u = v1 / norm1\n",
    "        v2u = v2 / norm2\n",
    "        dotv= np.clip(v1u.dot(v2u), -1,1)\n",
    "        angle= np.arccos(dotv)\n",
    "        if angle< 1e-9:\n",
    "            return np.vstack([center, end1])  # minimal angle => no arc\n",
    "        axis = np.cross(v1u, v2u)\n",
    "        a_len= np.linalg.norm(axis)\n",
    "        if a_len<1e-12:\n",
    "            # collinear\n",
    "            return np.vstack([center, end1, end2])\n",
    "        axis /= a_len\n",
    "\n",
    "        arc_pts= []\n",
    "        for i in range(num_points+1):\n",
    "            t= angle*(i/num_points)\n",
    "            rot_v = self._rotate_vector_around_axis(v1, axis, t)\n",
    "            arc_pts.append(center+ rot_v)\n",
    "        return np.array(arc_pts)\n",
    "\n",
    "    def _rotate_vector_around_axis(self, vec, axis, theta):\n",
    "        \"\"\"\n",
    "        Rodrigues rotation formula: v_rot = v*cosθ + (k×v)*sinθ + k*(k·v)*(1−cosθ).\n",
    "        \"\"\"\n",
    "        cos_t = np.cos(theta)\n",
    "        sin_t = np.sin(theta)\n",
    "        k = axis\n",
    "        v = vec\n",
    "        v_cos = v * cos_t\n",
    "        k_cross_v = np.cross(k, v)\n",
    "        v_sin = k_cross_v * sin_t\n",
    "        k_dot_v = np.dot(k, v)\n",
    "        v_k = k * (k_dot_v*(1 - cos_t))\n",
    "        return v_cos + v_sin + v_k\n",
    "\n",
    "    def _create_sphere_at_point(self, center, radius=0.00005, color=[0,0,0]):\n",
    "        \"\"\"\n",
    "        Create an Open3D sphere geometry placed at 'center' with the given 'radius'.\n",
    "        \"\"\"\n",
    "        sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius)\n",
    "        sphere.compute_vertex_normals()\n",
    "        # Move the sphere so its center is at 'center'\n",
    "        sphere.translate(center)\n",
    "        # Color the entire mesh\n",
    "        sphere.paint_uniform_color(color)\n",
    "        return sphere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainStemSegmentation:\n",
    "    \"\"\"\n",
    "    MainStemSegmentation: A class to segment the main stem from a full plant \n",
    "    point cloud using a graph-based approach. \n",
    "\n",
    "    Overview of the pipeline steps:\n",
    "      1) **Slicing & Clustering**:\n",
    "         - Slice the point cloud into horizontal sections.\n",
    "         - Cluster points in each slice using DBSCAN.\n",
    "         - Merge small or nearby clusters.\n",
    "\n",
    "      2) **Adjacency Construction**:\n",
    "         - Build adjacency between consecutive slices using two alternative methods:\n",
    "            (A) simple distance-based bipartite matching, \n",
    "            (B) a vertical matching approach that penalizes lateral offset and angle.\n",
    "\n",
    "      3) **Bridging Subgraphs & Negative-Cost Graph**:\n",
    "         - Attempt to unify disconnected subgraphs (bridge them) by incremental distance thresholds.\n",
    "         - Build a negative-cost DAG (raindrop model) to extract the trunk path.\n",
    "\n",
    "      4) **Labeling & Refinement**:\n",
    "         - Mark trunk-path nodes as 'stem', all others as 'leaf'.\n",
    "         - Identify branch-off nodes by degree threshold, then refine or remove outliers.\n",
    "\n",
    "      5) **Angle Extraction**:\n",
    "         - For each branch-off node, gather stem and leaf node coordinates, \n",
    "           fit lines, and compute the branch angle relative to the main stem.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    original_pcd : o3d.geometry.PointCloud\n",
    "        The original input point cloud.\n",
    "    pcd : o3d.geometry.PointCloud\n",
    "        A working copy of the point cloud (optionally centered or preprocessed).\n",
    "    points : np.ndarray\n",
    "        A (N, 3) array of the point cloud data from `pcd`.\n",
    "    slices : list of np.ndarray\n",
    "        A list of Z-sliced point subsets, each is Nx3.\n",
    "    slice_results : list of list of dict\n",
    "        Results of clustering in each slice. For slice i, \n",
    "        slice_results[i] is a list of cluster dicts with keys:\n",
    "        {'centroid': (3,) float array, 'points': (M,3) float array}.\n",
    "    n_slices : int\n",
    "        Number of slices determined or used.\n",
    "    adjacency_A : dict\n",
    "        A adjacency dictionary for “method A” (simple bipartite).\n",
    "    adjacency_B : dict\n",
    "        A adjacency dictionary for “method B” (vertical-based).\n",
    "    chosen_adjacency : dict\n",
    "        The final adjacency chosen (A or B) based on trunk cost.\n",
    "    cpoints_final : np.ndarray\n",
    "        (M,3) array of cluster centroids used in the final adjacency method.\n",
    "    node_map_final : dict\n",
    "        Mapping from (slice_idx, cluster_idx) -> node_id for final adjacency.\n",
    "    G_neg_final : nx.DiGraph\n",
    "        The final negative-cost DAG used for trunk extraction (inverted).\n",
    "    trunk_path : list of int\n",
    "        The node IDs forming the trunk path in `G_neg_final`.\n",
    "    top_node : int\n",
    "        The top-most node ID (highest z).\n",
    "    base_node : int\n",
    "        The base node ID in the trunk path (lowest on the DAG).\n",
    "    aggregated_centroids_map : list of tuple\n",
    "        Indexed by node_id => (slice_i, cluster_j).\n",
    "    branch_off_nodes : list of int\n",
    "        Node IDs identified as 'branch_off'.\n",
    "    branch_data : list of dict\n",
    "        Data of extracted branches => \n",
    "        { 'branch_off': <node_id>, 'stem_points': Nx3, 'leaf_points': Mx3, 'angle_degrees': float }.\n",
    "    labeled_pcd : o3d.geometry.PointCloud\n",
    "        A final color-labeled point cloud with 'stem' (red) vs 'leaf' (green) in original point space.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> pcd = o3d.io.read_point_cloud(\"myplant.ply\")\n",
    "    >>> segmentation = MainStemSegmentation(pcd)\n",
    "    >>> segmentation.slice_cloud_z(n_sections=80)\n",
    "    >>> segmentation.cluster_slices(base_scale=5.0, min_samples=30, dist_merge=0.02, min_pts_in_cluster=15)\n",
    "    >>> branch_data = segmentation.run_full_pipeline(alpha=1.0, beta=0.5,\n",
    "    ...                                              raindrop_alpha=1.0, raindrop_beta=1.0,\n",
    "    ...                                              use_trunk_axis=True, debug=True)\n",
    "    >>> segmentation.visualize_final_graph_types()\n",
    "    >>> segmentation.visualize_labeled_pcd()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, point_cloud: o3d.geometry.PointCloud):\n",
    "        \"\"\"\n",
    "        Initialize with a full plant point cloud.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        point_cloud : o3d.geometry.PointCloud\n",
    "            The input 3D plant point cloud (Open3D object).\n",
    "        \"\"\"\n",
    "        self.original_pcd = point_cloud\n",
    "        self.pcd = copy.deepcopy(point_cloud)\n",
    "        self.points = np.asarray(self.pcd.points)\n",
    "\n",
    "        # Initialize data structures\n",
    "        self.slices = []\n",
    "        self.slice_results = []\n",
    "        self.n_slices = 0\n",
    "\n",
    "        self.adjacency_A = {}\n",
    "        self.adjacency_B = {}\n",
    "        self.chosen_adjacency = {}\n",
    "        self.cpoints_final = None\n",
    "        self.node_map_final = {}\n",
    "        self.G_neg_final = None\n",
    "        self.trunk_path = []\n",
    "        self.top_node = None\n",
    "        self.base_node= None\n",
    "\n",
    "        self.all_main_stem_points_up   = []\n",
    "        self.all_main_stem_points_down = []\n",
    "        self.all_leaf_points           = []\n",
    "\n",
    "        self.aggregated_centroids_map = []\n",
    "        self.branch_off_nodes = []\n",
    "        self.branch_data = []\n",
    "        self.labeled_pcd = None\n",
    "\n",
    "    ##########################################################################\n",
    "    # STEP 1: Slicing & Clustering\n",
    "    ##########################################################################\n",
    "\n",
    "    def slice_cloud_z(self, n_sections=None, max_slices=80, show_hist=False):\n",
    "        \"\"\"\n",
    "        Slice the point cloud in Z by dividing [minZ..maxZ] into `n_sections`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_sections : int, optional\n",
    "            If None, we estimate a default from point count (N/500). \n",
    "            Else, we clamp to max_slices.\n",
    "        max_slices : int, default=80\n",
    "            Maximum number of slices.\n",
    "        show_hist : bool, default=False\n",
    "            Whether to display a histogram of the Z distribution (matplotlib).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        slices : list of np.ndarray\n",
    "            Each element is a subset of points belonging to that Z-slice.\n",
    "        \"\"\"\n",
    "        z_vals = self.points[:, 2]\n",
    "        z_min, z_max = z_vals.min(), z_vals.max()\n",
    "        if n_sections is None:\n",
    "            guess = max(1, len(self.points)//500)\n",
    "            n_sections = min(guess, max_slices)\n",
    "\n",
    "        zcuts = np.linspace(z_min, z_max, n_sections + 1)\n",
    "        slices = []\n",
    "        for i in range(n_sections):\n",
    "            mask = (z_vals >= zcuts[i]) & (z_vals < zcuts[i+1])\n",
    "            slices.append(self.points[mask])\n",
    "\n",
    "        if show_hist:\n",
    "            plt.figure()\n",
    "            plt.hist(z_vals, bins=50)\n",
    "            plt.title(\"Z distribution (debug)\")\n",
    "            plt.show()\n",
    "\n",
    "        self.slices = slices\n",
    "        self.n_slices = n_sections\n",
    "        return slices\n",
    "\n",
    "    def cluster_slices(self, base_scale=5.0, min_samples=30, dist_merge=0.02, min_pts_in_cluster=15):\n",
    "        \"\"\"\n",
    "        For each Z-slice, run DBSCAN, then merge close clusters and unify small clusters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_scale : float\n",
    "            Scale factor to multiply the median neighbor distance for DBSCAN's eps.\n",
    "        min_samples : int\n",
    "            Minimum samples in DBSCAN.\n",
    "        dist_merge : float\n",
    "            Threshold to merge cluster centroids within the same slice.\n",
    "        min_pts_in_cluster : int\n",
    "            Minimum points required to keep a cluster separate; else unify with nearest.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        slice_results : list of list of dict\n",
    "            For each slice i, a list of cluster dicts { 'centroid':..., 'points':... }.\n",
    "        \"\"\"\n",
    "        if not self.slices:\n",
    "            print(\"[WARN] No slices found => call slice_cloud_z first.\")\n",
    "            return []\n",
    "\n",
    "        slice_results = []\n",
    "        for s_pts in self.slices:\n",
    "            if len(s_pts) < min_samples:\n",
    "                # Not enough points => skip or store empty\n",
    "                slice_results.append([])\n",
    "                continue\n",
    "\n",
    "            # compute eps via base_scale * median_distance\n",
    "            nbrs = NearestNeighbors(n_neighbors=2).fit(s_pts)\n",
    "            dists,_ = nbrs.kneighbors(s_pts)\n",
    "            median_dist = np.median(dists[:,1])\n",
    "            eps_val = base_scale * median_dist\n",
    "\n",
    "            db = DBSCAN(eps=eps_val, min_samples=min_samples).fit(s_pts)\n",
    "            labels = db.labels_\n",
    "\n",
    "            # Gather clusters\n",
    "            cluster_list = []\n",
    "            for lbl in set(labels):\n",
    "                if lbl == -1:\n",
    "                    continue\n",
    "                mask = (labels == lbl)\n",
    "                cpts = s_pts[mask]\n",
    "                cent = cpts.mean(axis=0)\n",
    "                cluster_list.append({'centroid': cent, 'points': cpts})\n",
    "\n",
    "            # Merge clusters within dist_merge\n",
    "            merged = self._merge_in_slice_clusters(cluster_list, dist_thresh=dist_merge)\n",
    "            final  = self._unify_small_clusters(merged, min_pts_in_cluster=min_pts_in_cluster)\n",
    "            slice_results.append(final)\n",
    "\n",
    "        self.slice_results = slice_results\n",
    "        return slice_results\n",
    "\n",
    "    def _merge_in_slice_clusters(self, slice_clusters, dist_thresh=0.02):\n",
    "        \"\"\"\n",
    "        Merge clusters in a single slice whose centroids are < dist_thresh.\n",
    "\n",
    "        Internal helper used in `cluster_slices`.\n",
    "        \"\"\"\n",
    "        used = set()\n",
    "        merged = []\n",
    "        for i in range(len(slice_clusters)):\n",
    "            if i in used:\n",
    "                continue\n",
    "            cA_pts  = [slice_clusters[i]['points']]\n",
    "            cA_cent = slice_clusters[i]['centroid']\n",
    "            for j in range(i+1, len(slice_clusters)):\n",
    "                if j in used:\n",
    "                    continue\n",
    "                cB_cent = slice_clusters[j]['centroid']\n",
    "                dist_ij = np.linalg.norm(cA_cent - cB_cent)\n",
    "                if dist_ij < dist_thresh:\n",
    "                    cA_pts.append(slice_clusters[j]['points'])\n",
    "                    used.add(j)\n",
    "            merged_pts = np.vstack(cA_pts)\n",
    "            new_cent   = merged_pts.mean(axis=0)\n",
    "            merged.append({'centroid': new_cent, 'points': merged_pts})\n",
    "            used.add(i)\n",
    "        return merged\n",
    "\n",
    "    def _unify_small_clusters(self, slice_clusters, min_pts_in_cluster=15):\n",
    "        \"\"\"\n",
    "        If a cluster is smaller than min_pts_in_cluster, merge it with the nearest bigger one.\n",
    "        Internal helper for `cluster_slices`.\n",
    "        \"\"\"\n",
    "        final = []\n",
    "        small = []\n",
    "        for cdict in slice_clusters:\n",
    "            if len(cdict['points']) >= min_pts_in_cluster:\n",
    "                final.append(cdict)\n",
    "            else:\n",
    "                small.append(cdict)\n",
    "        if not final and small:\n",
    "            return []\n",
    "\n",
    "        for sc in small:\n",
    "            best_dist = float('inf')\n",
    "            best_idx  = -1\n",
    "            for idx_fc, fc in enumerate(final):\n",
    "                dist_ = np.linalg.norm(fc['centroid'] - sc['centroid'])\n",
    "                if dist_ < best_dist:\n",
    "                    best_dist = dist_\n",
    "                    best_idx  = idx_fc\n",
    "            if best_idx >=0:\n",
    "                merged_pts = np.vstack([final[best_idx]['points'], sc['points']])\n",
    "                new_cent   = merged_pts.mean(axis=0)\n",
    "                final[best_idx]['points']   = merged_pts\n",
    "                final[best_idx]['centroid'] = new_cent\n",
    "        return final\n",
    "\n",
    "    ##########################################################################\n",
    "    # STEP 2: Building Adjacency\n",
    "    ##########################################################################\n",
    "\n",
    "    def build_adjacency_bipartite(self, max_dist=0.1):\n",
    "        \"\"\"\n",
    "        Simple bipartite matching for slices i->i+1 using Euclidean distance < max_dist.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_dist : float\n",
    "            Distance threshold for linking clusters in consecutive slices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        adjacency : dict\n",
    "            Keys: (slice_idx, cluster_idx), \n",
    "            Values: list of neighbors => [(slice_idx+1, cluster_idx2), ...].\n",
    "        \"\"\"\n",
    "        adjacency = {}\n",
    "        for i in range(len(self.slice_results) - 1):\n",
    "            currC = self.slice_results[i]\n",
    "            nextC = self.slice_results[i+1]\n",
    "            m, n = len(currC), len(nextC)\n",
    "            if m==0 or n==0:\n",
    "                continue\n",
    "\n",
    "            cost_mat = np.zeros((m,n), dtype=float)\n",
    "            for r in range(m):\n",
    "                A = currC[r]['centroid']\n",
    "                for c in range(n):\n",
    "                    B = nextC[c]['centroid']\n",
    "                    cost_mat[r,c] = np.linalg.norm(A-B)\n",
    "\n",
    "            row_inds, col_inds = linear_sum_assignment(cost_mat)\n",
    "            for rr, cc in zip(row_inds, col_inds):\n",
    "                dist_val = cost_mat[rr, cc]\n",
    "                if dist_val< max_dist:\n",
    "                    adjacency[(i, rr)] = adjacency.get((i, rr), []) + [(i+1, cc)]\n",
    "        return adjacency\n",
    "\n",
    "    def build_adjacency_bipartite_vertical(self, trunk_axis, max_dist=1.5, alpha=1.0, beta=2.0):\n",
    "        \"\"\"\n",
    "        Another bipartite matching approach that penalizes horizontal offset + beta * angle to trunk.\n",
    "\n",
    "        cost = horizontal_offset + beta*angle_to_trunk\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trunk_axis : np.ndarray\n",
    "            A (3,) unit vector representing the approximate vertical axis.\n",
    "        max_dist : float\n",
    "            Threshold on the cost for linking clusters between slices.\n",
    "        alpha : float, optional\n",
    "            Not used directly here but you can incorporate if you want additional scaling.\n",
    "        beta : float\n",
    "            Weight factor multiplying the angle to trunk.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        adjacency : dict\n",
    "            Similar structure to build_adjacency_bipartite.\n",
    "        \"\"\"\n",
    "        adjacency = {}\n",
    "        # ensure trunk_axis is pointing \"up\"\n",
    "        trunk_axis = trunk_axis / (np.linalg.norm(trunk_axis)+1e-12)\n",
    "        if trunk_axis[2]<0:\n",
    "            trunk_axis = -trunk_axis\n",
    "\n",
    "        for i in range(len(self.slice_results)-1):\n",
    "            currC = self.slice_results[i]\n",
    "            nextC = self.slice_results[i+1]\n",
    "            m, n = len(currC), len(nextC)\n",
    "            if m==0 or n==0:\n",
    "                continue\n",
    "\n",
    "            cost_mat = np.zeros((m,n), dtype=float)\n",
    "            for r in range(m):\n",
    "                A = currC[r]['centroid']\n",
    "                for c in range(n):\n",
    "                    B = nextC[c]['centroid']\n",
    "                    vec    = B - A\n",
    "                    horiz  = np.linalg.norm(vec[:2])\n",
    "                    mag    = np.linalg.norm(vec)\n",
    "                    if mag<1e-12:\n",
    "                        angle = 0.0\n",
    "                    else:\n",
    "                        dot_val = max(-1.0, min(1.0, vec.dot(trunk_axis)/mag))\n",
    "                        angle   = math.acos(dot_val)\n",
    "                    cost_val = horiz + beta*angle\n",
    "                    cost_mat[r,c] = cost_val\n",
    "\n",
    "            row_inds, col_inds = linear_sum_assignment(cost_mat)\n",
    "            for rr, cc in zip(row_inds, col_inds):\n",
    "                val = cost_mat[rr, cc]\n",
    "                if val < max_dist:\n",
    "                    adjacency[(i, rr)] = adjacency.get((i, rr), []) + [(i+1, cc)]\n",
    "        return adjacency\n",
    "\n",
    "\n",
    "    ##########################################################################\n",
    "    # STEP 3: Building the Cost Graph & Extracting Trunk\n",
    "    ##########################################################################\n",
    "\n",
    "    def compute_principal_axis(self):\n",
    "        \"\"\"\n",
    "        Perform PCA on all cluster centroids to find the dominant principal axis.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        axis : np.ndarray (3,)\n",
    "            The principal axis of the centroids, oriented so that axis[2]>=0.\n",
    "        \"\"\"\n",
    "        all_c= []\n",
    "        for slc in self.slice_results:\n",
    "            for cd in slc:\n",
    "                all_c.append(cd['centroid'])\n",
    "        if len(all_c)<2:\n",
    "            return np.array([0,0,1], dtype=float)\n",
    "\n",
    "        arr = np.array(all_c)\n",
    "        arr_centered = arr - arr.mean(axis=0)\n",
    "        _,_,vT = np.linalg.svd(arr_centered, full_matrices=False)\n",
    "        axis = vT[0]\n",
    "        if axis[2]<0:\n",
    "            axis = -axis\n",
    "        return axis\n",
    "\n",
    "\n",
    "    def build_cost_graph(self, slice_results, adjacency, trunk_axis, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Build a directed graph with edges weighted by cost = dist + alpha*angle_to_trunk.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        slice_results : list of list of dict\n",
    "            The cluster info (each slice => cluster dicts).\n",
    "        adjacency : dict\n",
    "            The adjacency from one of the bipartite building methods.\n",
    "        trunk_axis : np.ndarray\n",
    "            (3,) approximate vertical axis. \n",
    "        alpha : float\n",
    "            Additional factor to scale the angle cost.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        G : nx.DiGraph\n",
    "            The cost graph.\n",
    "        node_map : dict\n",
    "            Maps (slice_i, cluster_j) -> node_id (int).\n",
    "        cpoints : np.ndarray\n",
    "            (N,3) array of cluster centroids.\n",
    "        \"\"\"\n",
    "        node_map = {}\n",
    "        cpoints  = []\n",
    "        nd_id=0\n",
    "        for i,clusts in enumerate(slice_results):\n",
    "            for j,cd in enumerate(clusts):\n",
    "                node_map[(i,j)] = nd_id\n",
    "                cpoints.append(cd['centroid'])\n",
    "                nd_id+=1\n",
    "        cpoints = np.array(cpoints)\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        for nd in range(len(cpoints)):\n",
    "            G.add_node(nd)\n",
    "\n",
    "        def costfunc(u,v):\n",
    "            d = np.linalg.norm(v - u)\n",
    "            if d<1e-9:\n",
    "                return 0\n",
    "            vec = (v - u)/d\n",
    "            dotv= np.clip(vec.dot(trunk_axis), -1,1)\n",
    "            angle= math.acos(dotv)\n",
    "            return d + alpha*angle\n",
    "\n",
    "        for (i,j), neighs in adjacency.items():\n",
    "            nd1 = node_map[(i,j)]\n",
    "            A   = cpoints[nd1]\n",
    "            for (k,l) in neighs:\n",
    "                nd2 = node_map[(k,l)]\n",
    "                B   = cpoints[nd2]\n",
    "                c_uv= costfunc(A,B)\n",
    "                c_vu= costfunc(B,A)\n",
    "                G.add_edge(nd1, nd2, weight=c_uv)\n",
    "                G.add_edge(nd2, nd1, weight=c_vu)\n",
    "\n",
    "        return G, node_map, cpoints\n",
    "\n",
    "\n",
    "\n",
    "    def build_raindrop_negcost_digraph(self, cpoints, adjacency, node_map,\n",
    "                                    alpha=1.0, beta=1.0, gamma=1.0, delta=2.0, trunk_axis=None,\n",
    "                                    reverse_z=False, debug=True):\n",
    "        \"\"\"\n",
    "        Build a negative-cost DAG for trunk extraction with branch awareness:\n",
    "        - If not reverse_z: edge (u->v) if z_v < z_u, cost includes branch point preference\n",
    "        - If reverse_z:     edge (v->u) if z_v >= z_u, symmetrical logic.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cpoints : np.ndarray\n",
    "            (N,3) centroids.\n",
    "        adjacency : dict\n",
    "            The adjacency dict from bipartite matching.\n",
    "        node_map : dict\n",
    "            (slice_i, cluster_j) -> node_id\n",
    "        alpha : float\n",
    "            Factor for horizontal cost.\n",
    "        beta : float\n",
    "            Factor for angle cost.\n",
    "        gamma : float\n",
    "            Factor for vertical preference cost.\n",
    "        delta : float\n",
    "            Factor for branch point preference (encourages paths through branch points).\n",
    "        trunk_axis : np.ndarray or None\n",
    "            The approximate vertical axis; if None, use [0,0,-1].\n",
    "        reverse_z : bool\n",
    "            If True, we invert the direction logic: \n",
    "            edges go from higher-z to lower-z.\n",
    "        debug : bool\n",
    "            If True, prints extra debug info.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        G : nx.DiGraph\n",
    "            The negative-cost DAG for trunk extraction.\n",
    "        \"\"\"\n",
    "        # Create the directed graph for path finding\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Create an undirected graph for branch point identification\n",
    "        undirected_graph = nx.Graph()\n",
    "        \n",
    "        N = len(cpoints)\n",
    "        \n",
    "        # Add all nodes to both graphs\n",
    "        for nd in range(N):\n",
    "            G.add_node(nd, branch_count=0, is_branch_point=False)\n",
    "            undirected_graph.add_node(nd)\n",
    "        \n",
    "        # Set up reference axis\n",
    "        if trunk_axis is None:\n",
    "            ref_axis = np.array([0,0,-1], dtype=float)\n",
    "        else:\n",
    "            ref_axis = trunk_axis / (np.linalg.norm(trunk_axis)+1e-12)\n",
    "            if ref_axis[2]>0:\n",
    "                ref_axis = -ref_axis\n",
    "                \n",
    "        def measure_angle(vec, axis):\n",
    "            mag = np.linalg.norm(vec)\n",
    "            if mag<1e-12:\n",
    "                return 0.0\n",
    "            dotv = max(-1.0, min(1.0, vec.dot(axis)/mag))\n",
    "            return math.acos(dotv)\n",
    "        \n",
    "        # First pass: Add edges to the undirected graph to identify branch points\n",
    "        for key, neighbors in adjacency.items():\n",
    "            ndA = node_map[key]\n",
    "            for nb in neighbors:\n",
    "                ndB = node_map[nb]\n",
    "                undirected_graph.add_edge(ndA, ndB)\n",
    "        \n",
    "        # Second pass: Identify branch points\n",
    "        branch_points = {}\n",
    "        for nd in undirected_graph.nodes():\n",
    "            degree = undirected_graph.degree(nd)\n",
    "            if degree >= 3:\n",
    "                branch_points[nd] = degree - 2  # Number of branches (excluding trunk connections)\n",
    "                G.nodes[nd]['branch_count'] = branch_points[nd]\n",
    "                G.nodes[nd]['is_branch_point'] = True\n",
    "        \n",
    "        # Third pass: Add directed edges with costs\n",
    "        total_edges= 0\n",
    "        for key, neighbors in adjacency.items():\n",
    "            ndA = node_map[key]\n",
    "            zA = cpoints[ndA][2]\n",
    "            for nb in neighbors:\n",
    "                ndB = node_map[nb]\n",
    "                zB = cpoints[ndB][2]\n",
    "\n",
    "                if not reverse_z:\n",
    "                    # normal => edge if zB < zA\n",
    "                    if zB < zA:\n",
    "                        vec = cpoints[ndB] - cpoints[ndA]\n",
    "                        horiz = np.linalg.norm(vec[:2])\n",
    "                        ang = measure_angle(vec, ref_axis)\n",
    "                        \n",
    "                        # Add vertical preference cost\n",
    "                        vertical_diff = abs(zB - zA)\n",
    "                        vertical_ratio = vertical_diff / (vertical_diff + horiz + 1e-10)\n",
    "                        vertical_cost = (1 - vertical_ratio) * gamma\n",
    "                        \n",
    "                        # Branch point preference\n",
    "                        branch_bonus = delta * (G.nodes[ndA].get('branch_count', 0) + \n",
    "                                            G.nodes[ndB].get('branch_count', 0))\n",
    "                        \n",
    "                        # Final cost (negative for longest path algorithm)\n",
    "                        cost_uv = -(alpha*horiz + beta*ang + vertical_cost + branch_bonus)\n",
    "                        \n",
    "                        # Add edge with computed weight\n",
    "                        G.add_edge(ndA, ndB, weight=cost_uv)\n",
    "                        total_edges += 1\n",
    "                \n",
    "                else:\n",
    "                    # reversed => edge if zB >= zA => (ndB->ndA)\n",
    "                    if zB >= zA:\n",
    "                        vec = cpoints[ndA] - cpoints[ndB]\n",
    "                        horiz = np.linalg.norm(vec[:2])\n",
    "                        ang = measure_angle(vec, ref_axis)\n",
    "                        \n",
    "                        # Add vertical preference cost\n",
    "                        vertical_diff = abs(zB - zA)\n",
    "                        vertical_ratio = vertical_diff / (vertical_diff + horiz + 1e-10)\n",
    "                        vertical_cost = (1 - vertical_ratio) * gamma\n",
    "                        \n",
    "                        # Branch point preference\n",
    "                        branch_bonus = delta * (G.nodes[ndA].get('branch_count', 0) + \n",
    "                                            G.nodes[ndB].get('branch_count', 0))\n",
    "                        \n",
    "                        # Final cost\n",
    "                        cost_vu = -(alpha*horiz + beta*ang + vertical_cost + branch_bonus)\n",
    "                        \n",
    "                        # Add edge with computed weight\n",
    "                        G.add_edge(ndB, ndA, weight=cost_vu)\n",
    "                        total_edges += 1\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] build_raindrop_negcost_digraph => #edges= {total_edges}\")\n",
    "            print(f\"[DEBUG] branch points detected: {len(branch_points)}\")\n",
    "            \n",
    "        return G\n",
    "\n",
    "    def longest_path_in_DAG_negcost(self, G, top_node_id, debug=True):\n",
    "        \"\"\"\n",
    "        Given a negative-cost DAG, find the path that yields minimal sum \n",
    "        (which is effectively the 'longest' path in positive sense).\n",
    "        \n",
    "        We do a topological sort, then DP to pick min-sum path from top_node_id.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.DiGraph\n",
    "            The negative-cost DAG.\n",
    "        top_node_id : int\n",
    "            The node from which we begin the path (highest z).\n",
    "        debug : bool\n",
    "            If True, prints debug info.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        base_node : int\n",
    "            The node at the other end of the minimal-cost path.\n",
    "        path : list of int\n",
    "            The sequence of nodes in that trunk path.\n",
    "        \"\"\"\n",
    "        topo_order = list(nx.topological_sort(G))\n",
    "        if top_node_id not in topo_order:\n",
    "            # fallback\n",
    "            return (top_node_id, [top_node_id])\n",
    "        \n",
    "        maxDist = {}\n",
    "        pred = {}\n",
    "        for nd in G.nodes():\n",
    "            maxDist[nd] = float('inf')  # we want minimal sum => store inf\n",
    "            pred[nd] = None\n",
    "        maxDist[top_node_id] = 0.0\n",
    "        \n",
    "        for nd in topo_order:\n",
    "            if maxDist[nd] == float('inf'):\n",
    "                continue\n",
    "            cost_nd = maxDist[nd]\n",
    "            for nb in G[nd]:\n",
    "                w = G[nd][nb]['weight']\n",
    "                alt = cost_nd + w\n",
    "                if alt < maxDist[nb]:\n",
    "                    maxDist[nb] = alt\n",
    "                    pred[nb] = nd\n",
    "        \n",
    "        best_node = top_node_id\n",
    "        best_val = maxDist[top_node_id]\n",
    "        for nd in G.nodes():\n",
    "            if maxDist[nd] < best_val:\n",
    "                best_val = maxDist[nd]\n",
    "                best_node = nd\n",
    "        \n",
    "        path = []\n",
    "        tmp = best_node\n",
    "        while tmp is not None:\n",
    "            path.append(tmp)\n",
    "            tmp = pred[tmp]\n",
    "        path.reverse()\n",
    "        \n",
    "        # Calculate branch statistics (do not modify function signature)\n",
    "        branch_count = sum(1 for node in path if G.nodes[node].get('is_branch_point', False))\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Longest path has {len(path)} nodes and {branch_count} branch points\")\n",
    "        \n",
    "        return (best_node, path)\n",
    "\n",
    "\n",
    "    def invert_graph_direction(self, G_in, cpoints):\n",
    "        \"\"\"\n",
    "        Produce a new DiGraph G_out in which each edge is reversed. \n",
    "        Copy node/edge attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        G_in : nx.DiGraph\n",
    "            The input directed graph.\n",
    "        cpoints : np.ndarray\n",
    "            Unused except if you wanted to condition on node positions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        G_out : nx.DiGraph\n",
    "            A new graph with reversed edges, preserving node attributes.\n",
    "        \"\"\"\n",
    "        G_out= nx.DiGraph()\n",
    "        for nd, attr in G_in.nodes(data=True):\n",
    "            G_out.add_node(nd, **attr)\n",
    "        for (u,v) in G_in.edges():\n",
    "            edata = G_in[u][v]\n",
    "            G_out.add_edge(v, u, **edata)\n",
    "        return G_out\n",
    "\n",
    "    ##########################################################################\n",
    "    # STEP 4: Labeling & Refinement\n",
    "    ##########################################################################\n",
    "\n",
    "    def label_main_stem_and_leaves(self, G, trunk_path):\n",
    "        \"\"\"\n",
    "        Mark trunk path nodes as 'stem', everything else as 'leaf'.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.DiGraph or nx.Graph\n",
    "            The graph to label in-place.\n",
    "        trunk_path : list of int\n",
    "            The node IDs that form the trunk path.\n",
    "        \"\"\"\n",
    "        stem_set= set(trunk_path)\n",
    "        for nd in G.nodes():\n",
    "            if nd in stem_set:\n",
    "                G.nodes[nd][\"type\"] = \"stem\"\n",
    "            else:\n",
    "                G.nodes[nd][\"type\"] = \"leaf\"\n",
    "\n",
    "    # def label_branch_off_nodes(self, G, min_degree=3):\n",
    "    #     \"\"\"\n",
    "    #     Mark any node with degree >= min_degree as 'branch_off'.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     G : nx.Graph or nx.DiGraph\n",
    "    #         The graph in which to label nodes.\n",
    "    #     min_degree : int\n",
    "    #         Degree threshold for labeling branch_off.\n",
    "    #     \"\"\"\n",
    "    #     for nd in G.nodes():\n",
    "    #         if G.degree(nd) >= min_degree:\n",
    "    #             G.nodes[nd]['type'] = 'branch_off'\n",
    "\n",
    "    def label_branch_off_nodes(self, G, min_degree=3):\n",
    "        \"\"\"\n",
    "        Mark any node with degree >= min_degree as 'branch_off'.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.Graph or nx.DiGraph\n",
    "            The graph in which to label nodes.\n",
    "        min_degree : int\n",
    "            Degree threshold for labeling branch_off.\n",
    "        \"\"\"\n",
    "        branch_points = []\n",
    "        for nd in G.nodes():\n",
    "            if G.degree(nd) >= min_degree:\n",
    "                G.nodes[nd]['type'] = 'branch_off'\n",
    "                G.nodes[nd]['branch_count'] = G.degree(nd) - 2  # Number of potential branches\n",
    "                branch_points.append(nd)\n",
    "        return branch_points\n",
    "\n",
    "    def refine_branch_off_nodes_immediate(self, G, min_stem=2, min_leaf=1):\n",
    "        \"\"\"\n",
    "        For each 'branch_off', check immediate neighbors. \n",
    "        If fewer than (min_stem) stem neighbors or (min_leaf) leaf neighbors, \n",
    "        re-label based on majority. \n",
    "        \"\"\"\n",
    "        def undirected_neighbors(u):\n",
    "            return set(G.successors(u)) | set(G.predecessors(u))\n",
    "\n",
    "        new_labels = {}\n",
    "        for nd in G.nodes():\n",
    "            if G.nodes[nd].get('type')=='branch_off':\n",
    "                nbrs= undirected_neighbors(nd)\n",
    "                stem_count= sum(G.nodes[x].get('type')=='stem' for x in nbrs)\n",
    "                leaf_count= sum(G.nodes[x].get('type')=='leaf' for x in nbrs)\n",
    "                if stem_count< min_stem or leaf_count< min_leaf:\n",
    "                    if stem_count> leaf_count:\n",
    "                        new_labels[nd]= 'stem'\n",
    "                    elif leaf_count> stem_count:\n",
    "                        new_labels[nd]= 'leaf'\n",
    "                    else:\n",
    "                        new_labels[nd]= 'outlier'\n",
    "        for k,v in new_labels.items():\n",
    "            G.nodes[k]['type']= v\n",
    "\n",
    "    def refine_close_branch_off_nodes(self, G, trunk_path, branch_off_nodes,\n",
    "                                      trunk_distance_threshold=4,\n",
    "                                      leaf_overlap_threshold=0.5):\n",
    "        \"\"\"\n",
    "        If two branch_off nodes are close along trunk_path (distance <= trunk_distance_threshold), \n",
    "        compare their sets of reachable leaf nodes. If overlap ratio >= leaf_overlap_threshold, \n",
    "        we unify by relabeling one as 'stem'.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.Graph or nx.DiGraph\n",
    "            The graph (with 'type' attributes).\n",
    "        trunk_path : list of int\n",
    "            The trunk path (ordered).\n",
    "        branch_off_nodes : list of int\n",
    "            The node IDs labeled 'branch_off'.\n",
    "        trunk_distance_threshold : int\n",
    "            If the trunk-index distance is <= this, we compare them.\n",
    "        leaf_overlap_threshold : float\n",
    "            If overlap ratio >= this, we unify (relabel) one as 'stem'.\n",
    "        \"\"\"\n",
    "        def undirected_neighbors(u):\n",
    "            return set(G.successors(u)) | set(G.predecessors(u))\n",
    "\n",
    "        from collections import deque\n",
    "\n",
    "        def get_leaf_set(b_off):\n",
    "            visited= set()\n",
    "            queue = deque()\n",
    "            leaf_nodes= set()\n",
    "            for nb in undirected_neighbors(b_off):\n",
    "                if G.nodes[nb].get('type')=='leaf':\n",
    "                    queue.append(nb)\n",
    "            while queue:\n",
    "                curr= queue.popleft()\n",
    "                if curr in visited:\n",
    "                    continue\n",
    "                visited.add(curr)\n",
    "                if G.nodes[curr].get('type')=='leaf':\n",
    "                    leaf_nodes.add(curr)\n",
    "                    for nxt in undirected_neighbors(curr):\n",
    "                        if nxt not in visited and nxt!=b_off and G.nodes[nxt].get('type')=='leaf':\n",
    "                            queue.append(nxt)\n",
    "            return leaf_nodes\n",
    "\n",
    "        trunk_index_map= { nd:i for i,nd in enumerate(trunk_path) }\n",
    "        branch_info={}\n",
    "        for b_off in branch_off_nodes:\n",
    "            idx= trunk_index_map.get(b_off, None)\n",
    "            if idx is not None:\n",
    "                lf_set= get_leaf_set(b_off)\n",
    "                branch_info[b_off]= (idx, lf_set)\n",
    "\n",
    "        sorted_boffs= sorted(branch_info.keys(), key=lambda x: branch_info[x][0])\n",
    "        to_relabel= set()\n",
    "\n",
    "        for i in range(len(sorted_boffs)):\n",
    "            b1= sorted_boffs[i]\n",
    "            if b1 in to_relabel:\n",
    "                continue\n",
    "            idx1, leafset1= branch_info[b1]\n",
    "            for j in range(i+1, len(sorted_boffs)):\n",
    "                b2= sorted_boffs[j]\n",
    "                if b2 in to_relabel:\n",
    "                    continue\n",
    "                idx2, leafset2= branch_info[b2]\n",
    "                dist_on_trunk= abs(idx2- idx1)\n",
    "                if dist_on_trunk<= trunk_distance_threshold:\n",
    "                    union_ = leafset1.union(leafset2)\n",
    "                    inter_ = leafset1.intersection(leafset2)\n",
    "                    if len(union_)>0:\n",
    "                        overlap= len(inter_)/ len(union_)\n",
    "                    else:\n",
    "                        overlap= 0.0\n",
    "                    if overlap>= leaf_overlap_threshold:\n",
    "                        to_relabel.add(b2)\n",
    "        for nd in to_relabel:\n",
    "            G.nodes[nd]['type']= 'stem'\n",
    "\n",
    "    \n",
    "    def refine_branch_off_by_leaf_count(self, G, trunk_path, min_leaves=2):\n",
    "        \"\"\"\n",
    "        Relabel branch_off nodes to stem if they have fewer than min_leaves connected leaves.\n",
    "        Traverses leaf connections through BFS to count total unique leaves.\n",
    "        \n",
    "        Parameters:\n",
    "            G (nx.Graph): The graph with labeled nodes\n",
    "            trunk_path (list): Main trunk node sequence\n",
    "            min_leaves (int): Minimum required leaf nodes (default=2)\n",
    "        \"\"\"\n",
    "        from collections import deque\n",
    "\n",
    "        def count_connected_leaves(start_node):\n",
    "            \"\"\"BFS to count all unique leaves connected through leaf nodes\"\"\"\n",
    "            visited = set()\n",
    "            queue = deque([start_node])\n",
    "            leaf_count = 0\n",
    "            \n",
    "            while queue:\n",
    "                current = queue.popleft()\n",
    "                if current in visited:\n",
    "                    continue\n",
    "                visited.add(current)\n",
    "                \n",
    "                if G.nodes[current].get('type') == 'leaf':\n",
    "                    leaf_count += 1\n",
    "                    # Only continue BFS through leaf nodes\n",
    "                    for neighbor in G.neighbors(current):\n",
    "                        if neighbor != start_node:  # Don't go back to branch_off\n",
    "                            queue.append(neighbor)\n",
    "            return leaf_count\n",
    "\n",
    "        # Get all current branch_off nodes not in trunk path\n",
    "        trunk_set = set(trunk_path)\n",
    "        branch_off_nodes = [\n",
    "            n for n in G.nodes\n",
    "            if G.nodes[n].get('type') == 'branch_off' and n not in trunk_set\n",
    "        ]\n",
    "\n",
    "        relabel_count = 0\n",
    "        for node in branch_off_nodes:\n",
    "            leaf_count = count_connected_leaves(node)\n",
    "            \n",
    "            if leaf_count < min_leaves:\n",
    "                # Preserve trunk path nodes, only relabel non-trunk branch_offs\n",
    "                if node not in trunk_set:\n",
    "                    G.nodes[node]['type'] = 'stem'\n",
    "                    relabel_count += 1\n",
    "\n",
    "        print(f\"Relabeled {relabel_count} branch_off nodes with <{min_leaves} leaves\")\n",
    "        return G\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##########################################################################\n",
    "    # STEP 5: Extract Branch Sections => Angles (Node-Based)\n",
    "    ##########################################################################\n",
    "\n",
    "    def extract_branch_sections_with_angles_node_based(\n",
    "        self, G, cpoints, trunk_path, branch_off_nodes,\n",
    "        n_main_stem=5,\n",
    "        n_leaf=5,\n",
    "        flip_if_obtuse=True,\n",
    "        min_leaf_for_angle=5,\n",
    "        max_bfs_depth=5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Node-based BFS approach to gather trunk coords near each branch_off => gather leaf => compute angle.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.Graph or nx.DiGraph\n",
    "            The final labeled graph.\n",
    "        cpoints : np.ndarray\n",
    "            Node coordinates (N,3), node_id => cpoints[node_id].\n",
    "        trunk_path : list of int\n",
    "            The IDs in the main stem trunk path.\n",
    "        branch_off_nodes : list of int\n",
    "            The node IDs labeled 'branch_off'.\n",
    "        n_main_stem : int\n",
    "            How many trunk nodes to gather above/below the branch_off.\n",
    "        n_leaf : int\n",
    "            Max leaf nodes to collect by BFS.\n",
    "        flip_if_obtuse : bool\n",
    "            If True, angles >90 deg => 180 - angle.\n",
    "        min_leaf_for_angle : int\n",
    "            If BFS finds fewer leaves => skip angle.\n",
    "        max_bfs_depth : int\n",
    "            BFS limit for counting leaves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        branch_data : list of dict\n",
    "            Each dict has keys:\n",
    "             'branch_off' : node_id,\n",
    "             'stem_points': Nx3 array,\n",
    "             'leaf_points': Mx3 array,\n",
    "             'angle_degrees': float\n",
    "        \"\"\"\n",
    "\n",
    "        def undirected_neighbors(u):\n",
    "            return set(G.successors(u)) | set(G.predecessors(u))\n",
    "\n",
    "        def count_leaf_nodes_bfs(start, depth_limit):\n",
    "            visited= set()\n",
    "            queue  = deque([(start,0)])\n",
    "            leaf_cnt= 0\n",
    "            while queue:\n",
    "                nd, dpt = queue.popleft()\n",
    "                if nd in visited:\n",
    "                    continue\n",
    "                visited.add(nd)\n",
    "                if G.nodes[nd].get('type')=='leaf':\n",
    "                    leaf_cnt+=1\n",
    "                if dpt< depth_limit:\n",
    "                    for nb in undirected_neighbors(nd):\n",
    "                        if nb not in visited:\n",
    "                            queue.append((nb, dpt+1))\n",
    "            return leaf_cnt\n",
    "\n",
    "        def collect_leaf_nodes_bfs(start, n_leaf):\n",
    "            visited= set()\n",
    "            queue  = deque()\n",
    "            leaves = []\n",
    "            # Start from immediate leaf neighbors\n",
    "            for nb in undirected_neighbors(start):\n",
    "                if G.nodes[nb].get('type')=='leaf':\n",
    "                    queue.append(nb)\n",
    "\n",
    "            while queue and len(leaves)< n_leaf:\n",
    "                curr= queue.popleft()\n",
    "                if curr in visited:\n",
    "                    continue\n",
    "                visited.add(curr)\n",
    "                if G.nodes[curr].get('type')=='leaf':\n",
    "                    leaves.append(curr)\n",
    "                    # expand neighbors\n",
    "                    for nxt in undirected_neighbors(curr):\n",
    "                        if nxt not in visited and G.nodes[nxt].get('type')=='leaf':\n",
    "                            queue.append(nxt)\n",
    "            return leaves\n",
    "\n",
    "        def fit_line_svd(pts):\n",
    "            arr= np.asarray(pts)\n",
    "            if arr.shape[0]<2:\n",
    "                return (None,None)\n",
    "            center= arr.mean(axis=0)\n",
    "            uu, ss, vh= np.linalg.svd(arr - center)\n",
    "            direction= vh[0]/ np.linalg.norm(vh[0])\n",
    "            return (center, direction)\n",
    "\n",
    "        data_out = []\n",
    "        trunk_set= set(trunk_path)\n",
    "\n",
    "        for b_off in branch_off_nodes:\n",
    "            if b_off not in trunk_set:\n",
    "                print(f\"[WARN] skip b_off= {b_off}, not trunk.\")\n",
    "                continue\n",
    "\n",
    "            leaf_cnt= count_leaf_nodes_bfs(b_off, max_bfs_depth)\n",
    "            if leaf_cnt< min_leaf_for_angle:\n",
    "                print(f\"[SKIP] b_off= {b_off}: only {leaf_cnt} leaves => skip angle.\")\n",
    "                continue\n",
    "\n",
    "            idx= trunk_path.index(b_off)\n",
    "            above_ids= trunk_path[idx+1: idx+1+n_main_stem]\n",
    "            below_ids= trunk_path[max(0, idx-n_main_stem): idx]\n",
    "            trunk_nodes= above_ids+ below_ids\n",
    "            trunk_points= [cpoints[tn] for tn in trunk_nodes if tn< len(cpoints)]\n",
    "            if len(trunk_points)<2:\n",
    "                continue\n",
    "\n",
    "            leaf_nodes= collect_leaf_nodes_bfs(b_off, n_leaf)\n",
    "            leaf_points= [cpoints[ln] for ln in leaf_nodes if ln< len(cpoints)]\n",
    "            if len(leaf_points)<2:\n",
    "                continue\n",
    "\n",
    "            # Fit lines\n",
    "            stem_center, stem_dir= fit_line_svd(trunk_points)\n",
    "            leaf_center, leaf_dir= fit_line_svd(leaf_points)\n",
    "            if stem_dir is None or leaf_dir is None:\n",
    "                continue\n",
    "\n",
    "            dot_val= np.clip(np.dot(stem_dir, leaf_dir),-1,1)\n",
    "            angle_deg= np.degrees(np.arccos(dot_val))\n",
    "            if flip_if_obtuse and angle_deg>90:\n",
    "                angle_deg= 180 - angle_deg\n",
    "\n",
    "            data_out.append({\n",
    "                'branch_off':   b_off,\n",
    "                'stem_points':  np.array(trunk_points),\n",
    "                'leaf_points':  np.array(leaf_points),\n",
    "                'angle_degrees': angle_deg\n",
    "            })\n",
    "            print(f\"[NODE-BASED-ANGLE] b_off= {b_off}, angle= {angle_deg:.2f}\")\n",
    "\n",
    "        return data_out\n",
    "\n",
    "    def map_labels_to_original_points_unified(self, G, slice_results, aggregated_map, original_pcd):\n",
    "        \"\"\"\n",
    "        Modified to include all original points, filling gaps via nearest-neighbor label propagation.\n",
    "        \"\"\"\n",
    "        color_map = {'stem': [1,0,0], 'leaf': [0,1,0], 'unknown': [0.6,0.6,0.6]}\n",
    "        label_map = {'stem': 0, 'leaf': 1, 'unknown': 2}\n",
    "\n",
    "        # Step 1: Generate initial labeled data from graph and slice_results\n",
    "        cluster_to_nodes = defaultdict(list)\n",
    "        for node_id, (si, cj) in enumerate(aggregated_map):\n",
    "            cluster_to_nodes[(si, cj)].append(node_id)\n",
    "\n",
    "        labeled_pts = []\n",
    "        labeled_cols = []\n",
    "        labeled_arr = []\n",
    "\n",
    "        for si, slice in enumerate(slice_results):\n",
    "            for cj, cluster in enumerate(slice):\n",
    "                nodes = cluster_to_nodes.get((si, cj), [])\n",
    "                types = []\n",
    "                for nd in nodes:\n",
    "                    t = G.nodes[nd].get('type', 'unknown')\n",
    "                    if t == 'branch_off':\n",
    "                        t = 'stem'\n",
    "                    types.append(t)\n",
    "                final_type = 'stem' if 'stem' in types else 'leaf' if 'leaf' in types else 'unknown'\n",
    "                col = color_map[final_type]\n",
    "                lbl = label_map[final_type]\n",
    "                for p in cluster['points']:\n",
    "                    labeled_pts.append(p)\n",
    "                    labeled_cols.append(col)\n",
    "                    labeled_arr.append([p[0], p[1], p[2], lbl])\n",
    "        labeled_arr = np.array(labeled_arr, dtype=float)\n",
    "        # Step 2: Identify missing points in the original_pcd and propagate labels\n",
    "        original_points = np.asarray(original_pcd.points)\n",
    "        if len(labeled_pts) == 0:\n",
    "            # Edge case: No labels found; mark all as unknown\n",
    "            filled_labels = np.full((len(original_points), 1), 2)\n",
    "        else:\n",
    "            # Build KDTree from initially labeled points\n",
    "            labeled_pcd = o3d.geometry.PointCloud()\n",
    "            labeled_pcd.points = o3d.utility.Vector3dVector(np.array(labeled_pts))\n",
    "            tree = o3d.geometry.KDTreeFlann(labeled_pcd)\n",
    "\n",
    "            filled_labels = []\n",
    "            radius = 1e-6  # Adjust based on point cloud density (e.g., 1mm for real-world data)\n",
    "            for p in original_points:\n",
    "                # Check if the point is already labeled (exact match)\n",
    "                [k, idx, _] = tree.search_radius_vector_3d(p, radius)\n",
    "                if k > 0:\n",
    "                    lbl = labeled_arr[idx[0], 3]\n",
    "                else:\n",
    "                    # Find nearest neighbor and inherit label\n",
    "                    [k, idx, _] = tree.search_knn_vector_3d(p, 1)\n",
    "                    lbl = labeled_arr[idx[0], 3] if k > 0 else 2\n",
    "                filled_labels.append(lbl)\n",
    "            filled_labels = np.array(filled_labels)\n",
    "\n",
    "        # Step 3: Create output with ALL original points\n",
    "        out_pcd = o3d.geometry.PointCloud()\n",
    "        out_pcd.points = original_pcd.points\n",
    "        out_colors = np.array([color_map['stem' if lbl == 0 else 'leaf' if lbl == 1 else 'unknown'] \n",
    "                            for lbl in filled_labels])\n",
    "        out_pcd.colors = o3d.utility.Vector3dVector(out_colors)\n",
    "        labeled_arr = np.hstack([original_points, filled_labels.reshape(-1, 1)])\n",
    "\n",
    "        return out_pcd, labeled_arr\n",
    "\n",
    "\n",
    "    ##########################################################################\n",
    "    # ------------------- INTERNAL BRIDGING METHODS -------------------------\n",
    "    ##########################################################################\n",
    "\n",
    "    def _bridge_subgraphs_full_increasing_debug(\n",
    "        self,\n",
    "        adjacency,\n",
    "        node_map,\n",
    "        cpoints,\n",
    "        initial_dist=0.05,\n",
    "        dist_step=0.01,\n",
    "        max_dist=0.5,\n",
    "        max_passes_each=3,\n",
    "        debug=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Iteratively unify subgraphs with bridging distance from initial_dist up to max_dist.\n",
    "        Calls _bridge_subgraphs_full_debug internally.\n",
    "        \"\"\"\n",
    "        bridging_dist= initial_dist\n",
    "        final_subg= None\n",
    "\n",
    "        while bridging_dist <= max_dist:\n",
    "            if debug:\n",
    "                print(f\"[_bridge_subgraphs_full_increasing_debug] bridging_dist= {bridging_dist:.3f}\")\n",
    "\n",
    "            subg_list= self._bridge_subgraphs_full_debug(\n",
    "                adjacency= adjacency,\n",
    "                node_map= node_map,\n",
    "                cpoints= cpoints,\n",
    "                bridging_dist= bridging_dist,\n",
    "                max_passes= max_passes_each,\n",
    "                debug= debug\n",
    "            )\n",
    "            if len(subg_list)<=1:\n",
    "                if debug:\n",
    "                    print(f\"[_bridge_subgraphs_full_increasing_debug] => single subgraph at dist={bridging_dist:.3f}\")\n",
    "                return subg_list, bridging_dist\n",
    "\n",
    "            bridging_dist+= dist_step\n",
    "            final_subg= subg_list\n",
    "\n",
    "        if debug and final_subg:\n",
    "            print(f\"[_bridge_subgraphs_full_increasing_debug] Reached bridging_dist={bridging_dist:.3f} > max_dist => {len(final_subg)} subgraphs remain.\")\n",
    "        return final_subg, bridging_dist\n",
    "\n",
    "    def _bridge_subgraphs_full_debug(\n",
    "        self,\n",
    "        adjacency,\n",
    "        node_map,\n",
    "        cpoints,\n",
    "        bridging_dist=0.05,\n",
    "        max_passes=5,\n",
    "        debug=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Repeatedly call _bridge_subgraphs_once_debug until no changes or fully connected.\n",
    "        \"\"\"\n",
    "        for pass_num in range(max_passes):\n",
    "            if debug:\n",
    "                print(f\"[_bridge_subgraphs_full_debug] pass={pass_num}\")\n",
    "            subg_list, changed= self._bridge_subgraphs_once_debug(\n",
    "                adjacency,\n",
    "                node_map,\n",
    "                cpoints,\n",
    "                bridging_dist= bridging_dist,\n",
    "                debug= debug\n",
    "            )\n",
    "            if not changed:\n",
    "                if debug:\n",
    "                    print(f\"[_bridge_subgraphs_full_debug] pass={pass_num} => no more changes => stop.\")\n",
    "                return subg_list\n",
    "            if len(subg_list)<=1:\n",
    "                if debug:\n",
    "                    print(f\"[_bridge_subgraphs_full_debug] pass={pass_num} => now fully connected.\")\n",
    "                return subg_list\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[_bridge_subgraphs_full_debug] Reached max_passes={max_passes}, still have {len(subg_list)} subgraphs.\")\n",
    "        return subg_list\n",
    "\n",
    "    def _bridge_subgraphs_once_debug(\n",
    "        self,\n",
    "        adjacency,\n",
    "        node_map,\n",
    "        cpoints,\n",
    "        bridging_dist=0.05,\n",
    "        debug=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        One pass bridging: find disconnected subgraphs, unify those w/ dist <= bridging_dist.\n",
    "        \"\"\"\n",
    "        subg_list= self._find_subgraphs_debug(adjacency, debug=debug)\n",
    "        n_comps= len(subg_list)\n",
    "        if n_comps<=1:\n",
    "            if debug:\n",
    "                print(f\"[_bridge_subgraphs_once_debug] Only {n_comps} subgraph => no bridging needed.\")\n",
    "            return subg_list, False\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[_bridge_subgraphs_once_debug] Found {n_comps} subgraphs => bridgingDist={bridging_dist:.3f}\")\n",
    "\n",
    "        # build subgraph_id\n",
    "        subgraph_id= {}\n",
    "        for i, comp in enumerate(subg_list):\n",
    "            for nd in comp:\n",
    "                subgraph_id[nd]= i\n",
    "\n",
    "        # gather bridging candidates\n",
    "        bridging_candidates= []\n",
    "        for i in range(n_comps):\n",
    "            for j in range(i+1, n_comps):\n",
    "                dist_val, (ndA, ndB)= self._find_closest_pair_between_subgraphs_debug(\n",
    "                    subg_list[i], subg_list[j],\n",
    "                    node_map, cpoints, debug=False\n",
    "                )\n",
    "                bridging_candidates.append((dist_val, ndA, ndB, i, j))\n",
    "\n",
    "        bridging_candidates.sort(key= lambda x: x[0])\n",
    "\n",
    "        changed= False\n",
    "        for (dist_val, ndA, ndB, iA, iB) in bridging_candidates:\n",
    "            if dist_val> bridging_dist:\n",
    "                break\n",
    "            if subgraph_id[ndA]== subgraph_id[ndB]:\n",
    "                continue\n",
    "            if debug:\n",
    "                print(f\"[_bridge_subgraphs_once_debug] bridging subgraph {subgraph_id[ndA]} & {subgraph_id[ndB]} via nodes {ndA}--{ndB}, dist={dist_val:.3f}\")\n",
    "\n",
    "            self._safe_append_edge(adjacency, ndA, ndB)\n",
    "            changed= True\n",
    "\n",
    "            # optional vertical adjacency\n",
    "            i_slice, i_cluster= ndA\n",
    "            k_slice, k_cluster= ndB\n",
    "            if k_slice== i_slice+1:\n",
    "                if debug:\n",
    "                    print(f\" => Also adding vertical adjacency {ndA} -> {ndB}\")\n",
    "                if ndB not in adjacency[ndA]:\n",
    "                    adjacency[ndA].append(ndB)\n",
    "            elif i_slice== k_slice+1:\n",
    "                if debug:\n",
    "                    print(f\" => Also adding vertical adjacency {ndB} -> {ndA}\")\n",
    "                if ndA not in adjacency[ndB]:\n",
    "                    adjacency[ndB].append(ndA)\n",
    "\n",
    "            # unify subgraphs\n",
    "            oldID= subgraph_id[ndB]\n",
    "            newID= subgraph_id[ndA]\n",
    "            for ndX in subg_list[oldID]:\n",
    "                subgraph_id[ndX]= newID\n",
    "            subg_list[newID].update(subg_list[oldID])\n",
    "            subg_list[oldID].clear()\n",
    "\n",
    "        # reassemble ignoring empties\n",
    "        final_subg= []\n",
    "        for comp in subg_list:\n",
    "            if len(comp)>0:\n",
    "                final_subg.append(comp)\n",
    "\n",
    "        return final_subg, changed\n",
    "\n",
    "    def _safe_append_edge(self, adjacency, ndA, ndB):\n",
    "        \"\"\"Ensure adjacency[ndA], adjacency[ndB] exist, then link them both ways.\"\"\"\n",
    "        if ndA not in adjacency:\n",
    "            adjacency[ndA]= []\n",
    "        if ndB not in adjacency:\n",
    "            adjacency[ndB]= []\n",
    "        adjacency[ndA].append(ndB)\n",
    "        adjacency[ndB].append(ndA)\n",
    "\n",
    "    def _find_subgraphs_debug(self, adjacency, debug=True):\n",
    "        \"\"\"\n",
    "        BFS subgraph detection with debug prints.\n",
    "        \"\"\"\n",
    "        visited= set()\n",
    "        subgraphs= []\n",
    "        all_nodes= list(adjacency.keys())\n",
    "        if debug:\n",
    "            print(f\"[_find_subgraphs_debug] total nodes in adjacency= {len(all_nodes)}\")\n",
    "\n",
    "        for node in all_nodes:\n",
    "            if node not in visited:\n",
    "                comp= set()\n",
    "                queue= deque([node])\n",
    "                visited.add(node)\n",
    "                if debug:\n",
    "                    print(f\" => BFS start node= {node}\")\n",
    "                while queue:\n",
    "                    curr= queue.popleft()\n",
    "                    comp.add(curr)\n",
    "                    neighbors= adjacency.get(curr, [])\n",
    "                    for nb in neighbors:\n",
    "                        if nb not in visited:\n",
    "                            visited.add(nb)\n",
    "                            queue.append(nb)\n",
    "                subgraphs.append(comp)\n",
    "                if debug:\n",
    "                    print(f\" => subgraph found => size= {len(comp)}\")\n",
    "\n",
    "        if debug:\n",
    "            print(f\" => total subgraphs= {len(subgraphs)}\")\n",
    "        return subgraphs\n",
    "\n",
    "    def _find_closest_pair_between_subgraphs_debug(self, subgA, subgB, node_map, cpoints, debug=False):\n",
    "        \"\"\"\n",
    "        Minimal 3D distance among all pairs => (distVal, (ndA, ndB)).\n",
    "        \"\"\"\n",
    "        best_dist= float('inf')\n",
    "        best_pair= (None,None)\n",
    "        for ndA in subgA:\n",
    "            idxA= node_map[ndA]\n",
    "            pA= cpoints[idxA]\n",
    "            for ndB in subgB:\n",
    "                idxB= node_map[ndB]\n",
    "                pB= cpoints[idxB]\n",
    "                d= np.linalg.norm(pA- pB)\n",
    "                if d< best_dist:\n",
    "                    best_dist= d\n",
    "                    best_pair= (ndA, ndB)\n",
    "        if debug:\n",
    "            print(f\" => find_closest_pair_between_subgraphs => dist={best_dist:.3f}, pair={best_pair}\")\n",
    "        return best_dist, best_pair\n",
    "\n",
    "\n",
    "\n",
    "    ##########################################################################\n",
    "    # MASTER RUN PIPELINE\n",
    "    ##########################################################################\n",
    "\n",
    "\n",
    "    def run_full_pipeline(\n",
    "        self,\n",
    "        alpha=1.0,\n",
    "        beta=0.5,\n",
    "        raindrop_alpha=1.0,\n",
    "        raindrop_beta=1.0,\n",
    "        gamma=2.0,\n",
    "        delta=1.0,\n",
    "        use_trunk_axis=True,\n",
    "        debug=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Reorder the operations to match the standalone script’s logic/sequence:\n",
    "        1) slicing & clustering\n",
    "        2) build adjacency A & B\n",
    "        3) bridging subgraphs\n",
    "        4) build negative-cost DAG, trunk extraction\n",
    "        5) label trunk => 'stem' & everything else => 'leaf'\n",
    "        6) label_branch_off_nodes(min_degree=3)\n",
    "            => now we see branch_off if degree≥3\n",
    "        7) (optional) refine branch_off nodes\n",
    "        8) compute angles\n",
    "        9) map final labels => labeled_pcd\n",
    "        \"\"\"\n",
    "        # ---------------------------------------------------------------\n",
    "        # 1) Slicing + clustering if not already done\n",
    "        # ---------------------------------------------------------------\n",
    "        if not self.slices:\n",
    "            self.slice_cloud_z(n_sections=None, max_slices=80, show_hist=False)\n",
    "        if not self.slice_results:\n",
    "            self.cluster_slices(\n",
    "                base_scale=5.0, \n",
    "                min_samples=5, # 5, 8\n",
    "                dist_merge=0.01, #0.01\n",
    "                min_pts_in_cluster=15\n",
    "            )\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 2) Compute trunk axis => used in adjacency\n",
    "        # ---------------------------------------------------------------\n",
    "        trunk_axis = self.compute_principal_axis()\n",
    "        if debug:\n",
    "            print(\"[DEBUG] trunk_axis =\", trunk_axis)\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 3) Build adjacency (A + B), bridging, negative-cost DAG\n",
    "        # ---------------------------------------------------------------\n",
    "        \n",
    "        ### --- adjacency A\n",
    "        adjA = self.build_adjacency_bipartite(max_dist=0.1)\n",
    "        GA, node_mapA, cpointsA = self.build_cost_graph(self.slice_results, adjA, trunk_axis, alpha=alpha)\n",
    "\n",
    "        # bridging subgraphs => same as your script\n",
    "        adjA_copy = copy.deepcopy(adjA)\n",
    "        final_subgA, used_distA = self._bridge_subgraphs_full_increasing_debug(\n",
    "            adjacency=adjA_copy,\n",
    "            node_map=node_mapA,\n",
    "            cpoints=cpointsA,\n",
    "            debug=debug\n",
    "        )\n",
    "        if debug:\n",
    "            print(f\"[A] bridging => final bridging_dist= {used_distA:.3f}, subg= {len(final_subgA)}\")\n",
    "\n",
    "        GnegA = self.build_raindrop_negcost_digraph(\n",
    "            cpointsA, adjA_copy, node_mapA,\n",
    "            alpha=raindrop_alpha,\n",
    "            beta=raindrop_beta,\n",
    "            gamma=gamma, \n",
    "            delta=delta,\n",
    "            trunk_axis=trunk_axis if use_trunk_axis else None,\n",
    "            reverse_z=True,\n",
    "            debug=debug\n",
    "        )\n",
    "        zA = cpointsA[:, 2]\n",
    "        topA = int(zA.argmax())\n",
    "        baseA, trunkA = self.longest_path_in_DAG_negcost(GnegA, topA, debug=debug)\n",
    "        costA = 0.0\n",
    "        for i2 in range(len(trunkA) - 1):\n",
    "            costA += GnegA[trunkA[i2]][trunkA[i2+1]]['weight']\n",
    "        if debug:\n",
    "            print(f\"[A] trunk => base={baseA}, top={topA}, cost={costA:.3f}\")\n",
    "\n",
    "        ### --- adjacency B\n",
    "        adjB = self.build_adjacency_bipartite_vertical(\n",
    "            trunk_axis, max_dist=1.5, alpha=alpha, beta=beta\n",
    "        )\n",
    "        GB, node_mapB, cpointsB = self.build_cost_graph(self.slice_results, adjB, trunk_axis, alpha=alpha)\n",
    "\n",
    "        adjB_copy = copy.deepcopy(adjB)\n",
    "        final_subgB, used_distB = self._bridge_subgraphs_full_increasing_debug(\n",
    "            adjacency=adjB_copy,\n",
    "            node_map=node_mapB,\n",
    "            cpoints=cpointsB,\n",
    "            debug=debug\n",
    "        )\n",
    "        if debug:\n",
    "            print(f\"[B] bridging => final bridging_dist= {used_distB:.3f}, subg= {len(final_subgB)}\")\n",
    "\n",
    "        GnegB = self.build_raindrop_negcost_digraph(\n",
    "            cpointsB, adjB_copy, node_mapB,\n",
    "            alpha=raindrop_alpha,\n",
    "            beta=raindrop_beta,\n",
    "            gamma=gamma, \n",
    "            delta=delta,\n",
    "            trunk_axis=trunk_axis if use_trunk_axis else None,\n",
    "            reverse_z=True,\n",
    "            debug=debug\n",
    "        )\n",
    "        zB = cpointsB[:,2]\n",
    "        topB = int(zB.argmax())\n",
    "        baseB, trunkB = self.longest_path_in_DAG_negcost(GnegB, topB, debug=debug)\n",
    "        costB = 0.0\n",
    "        for i2 in range(len(trunkB) - 1):\n",
    "            costB += GnegB[trunkB[i2]][trunkB[i2 + 1]]['weight']\n",
    "        if debug:\n",
    "            print(f\"[B] trunk => base={baseB}, top={topB}, cost={costB:.3f}\")\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 4) Choose whichever adjacency => trunk cost is more negative\n",
    "        # ---------------------------------------------------------------\n",
    "        if costA < costB:\n",
    "            self.chosen_adjacency = adjA\n",
    "            self.cpoints_final    = cpointsA\n",
    "            self.node_map_final  = node_mapA\n",
    "            self.G_neg_final     = GnegA\n",
    "            self.trunk_path      = trunkA\n",
    "            self.base_node       = baseA\n",
    "            self.top_node        = topA\n",
    "            if debug:\n",
    "                print(f\"[MASTER] chosen adjacency= A, trunk_cost= {costA:.3f}\")\n",
    "        else:\n",
    "            self.chosen_adjacency = adjB\n",
    "            self.cpoints_final    = cpointsB\n",
    "            self.node_map_final  = node_mapB\n",
    "            self.G_neg_final     = GnegB\n",
    "            self.trunk_path      = trunkB\n",
    "            self.base_node       = baseB\n",
    "            self.top_node        = topB\n",
    "            if debug:\n",
    "                print(f\"[MASTER] chosen adjacency= B, trunk_cost= {costB:.3f}\")\n",
    "\n",
    "        # Optionally invert direction\n",
    "        self.G_neg_final = self.invert_graph_direction(self.G_neg_final, self.cpoints_final)\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 5) Label trunk => 'stem', others => 'leaf'\n",
    "        # ---------------------------------------------------------------\n",
    "        self.label_main_stem_and_leaves(self.G_neg_final, self.trunk_path)\n",
    "\n",
    "        # 6) label_branch_off_nodes => now we get nodes with degree≥3 => 'branch_off'\n",
    "        self.label_branch_off_nodes(self.G_neg_final, min_degree=3)\n",
    "\n",
    "\n",
    "    \n",
    "        # # Add leaf count check\n",
    "        # self.refine_branch_off_by_leaf_count(\n",
    "        #     self.G_neg_final,\n",
    "        #     self.trunk_path,\n",
    "        #     min_leaves=2  # Adjust based on plant morphology\n",
    "        # )\n",
    "\n",
    "        # Build aggregated map => node_id => (slice_i, cluster_j)\n",
    "        ag_map = [None]* len(self.cpoints_final)\n",
    "        for (si,cj), nd in self.node_map_final.items():\n",
    "            ag_map[nd] = (si,cj)\n",
    "        self.aggregated_centroids_map = ag_map\n",
    "\n",
    "        # 7) (optional) REFINE => if you still want outlier removal or \n",
    "        #    the \"2 stem + 1 leaf neighbor\" requirement,\n",
    "        #    but do it AFTER we've labeled them as branch_off. \n",
    "        #    If you want to skip them to match the script exactly, \n",
    "        #    comment these out:\n",
    "        # ---------------------------------------------------------------\n",
    "        if debug:\n",
    "            print(\"[DEBUG] => now refine outlier branch_off, if any.\")\n",
    "\n",
    "        self.refine_branch_off_nodes_immediate(self.G_neg_final, min_stem=2, min_leaf=1)\n",
    "        boffs = [\n",
    "            nd for nd in self.G_neg_final.nodes()\n",
    "            if self.G_neg_final.nodes[nd].get('type') == 'branch_off'\n",
    "        ]\n",
    "\n",
    "        \n",
    "        self.refine_close_branch_off_nodes(\n",
    "            self.G_neg_final,\n",
    "            self.trunk_path,\n",
    "            boffs,\n",
    "            trunk_distance_threshold=4,\n",
    "            leaf_overlap_threshold=0.8\n",
    "        )\n",
    "        self.branch_off_nodes = [\n",
    "            nd for nd in self.G_neg_final.nodes()\n",
    "            if self.G_neg_final.nodes[nd].get('type')=='branch_off'\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "        # 9) unify labels => original points => color-coded PCD\n",
    "        # ---------------------------------------------------------------\n",
    "        self.labeled_pcd, labeled_arr = self.map_labels_to_original_points_unified(\n",
    "            self.G_neg_final,\n",
    "            self.slice_results,\n",
    "            self.aggregated_centroids_map,\n",
    "            self.original_pcd\n",
    "        )\n",
    "        if debug:\n",
    "            print(f\"[INFO] Created labeled PCD => #points= {len(self.labeled_pcd.points)}\")\n",
    "            print(\"[END OF PIPELINE] => main stem & branch_off labeled => done.\")\n",
    "\n",
    "        return self.branch_data\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    ##########################################################################\n",
    "    # Optional Visualization Helpers\n",
    "    ##########################################################################\n",
    "\n",
    "    def debug_print_graph(self, G=None):\n",
    "        \"\"\"\n",
    "        Print node and edge information for debugging.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        G : nx.Graph or nx.DiGraph, optional\n",
    "            If None, uses self.G_neg_final.\n",
    "        \"\"\"\n",
    "        if G is None:\n",
    "            G= self.G_neg_final\n",
    "        print(\"[DEBUG PRINT GRAPH]\")\n",
    "        if not G:\n",
    "            print(\"No graph to print.\")\n",
    "            return\n",
    "        print(f\"  #nodes= {G.number_of_nodes()}, #edges= {G.number_of_edges()}\")\n",
    "        for nd in G.nodes():\n",
    "            t= G.nodes[nd].get('type','?')\n",
    "            coord= None\n",
    "            if self.cpoints_final is not None and nd<len(self.cpoints_final):\n",
    "                coord= self.cpoints_final[nd]\n",
    "            print(f\" Node={nd}, type={t}, coord= {coord}\")\n",
    "        print(\"Edges =>\")\n",
    "        for (u,v) in G.edges():\n",
    "            w= G[u][v].get('weight', None)\n",
    "            print(f\"  Edge=({u}->{v}), w={w:.3f}\" if w else f\"  Edge=({u}->{v})\")\n",
    "        print(\"===\")\n",
    "\n",
    "    def visualize_final_graph_types(self):\n",
    "        \"\"\"\n",
    "        Show the final G_neg_final with color-coded node types:\n",
    "        'stem' -> red, 'branch_off' -> blue, 'leaf' -> green, etc.\n",
    "        Points and lines are displayed larger for improved readability.\n",
    "        \"\"\"\n",
    "        if self.G_neg_final is None:\n",
    "            print(\"[WARN] no final graph => run pipeline first.\")\n",
    "            return\n",
    "\n",
    "        node_positions = []\n",
    "        node_colors = []\n",
    "        nlist = list(self.G_neg_final.nodes())\n",
    "        for nd in nlist:\n",
    "            if (self.cpoints_final is not None) and (0 <= nd < len(self.cpoints_final)):\n",
    "                node_positions.append(self.cpoints_final[nd])\n",
    "            else:\n",
    "                node_positions.append([0, 0, 0])\n",
    "            node_type = self.G_neg_final.nodes[nd].get('type', 'unknown')\n",
    "            if node_type == 'stem':\n",
    "                node_colors.append([1, 0, 0])\n",
    "            elif node_type == 'branch_off':\n",
    "                node_colors.append([0, 0, 1])\n",
    "            elif node_type == 'leaf':\n",
    "                node_colors.append([0, 1, 0])\n",
    "            else:\n",
    "                node_colors.append([0.5, 0.5, 0.5])\n",
    "\n",
    "        arr_pos = np.array(node_positions, dtype=float)\n",
    "        arr_col = np.array(node_colors, dtype=float)\n",
    "\n",
    "        pcd_nodes = o3d.geometry.PointCloud()\n",
    "        pcd_nodes.points = o3d.utility.Vector3dVector(arr_pos)\n",
    "        pcd_nodes.colors = o3d.utility.Vector3dVector(arr_col)\n",
    "\n",
    "        edges = []\n",
    "        for nd in nlist:\n",
    "            for nb in self.G_neg_final.neighbors(nd):\n",
    "                if nb > nd:\n",
    "                    edges.append([nd, nb])\n",
    "        ls = o3d.geometry.LineSet()\n",
    "        ls.points = o3d.utility.Vector3dVector(arr_pos)\n",
    "        ls.lines = o3d.utility.Vector2iVector(np.array(edges, dtype=int))\n",
    "        black = [[0, 0, 0]] * len(edges)\n",
    "        ls.colors = o3d.utility.Vector3dVector(black)\n",
    "\n",
    "        # Use the Visualizer to adjust render options.\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window(window_name=\"Final Graph + Types\")\n",
    "        vis.add_geometry(pcd_nodes)\n",
    "        vis.add_geometry(ls)\n",
    "        \n",
    "        # Get the render options and increase point size and line width.\n",
    "        opt = vis.get_render_option()\n",
    "        opt.point_size = 10.0  # Increase point size (default is around 1.0-5.0)\n",
    "        opt.line_width = 3.0   # Increase line width (default is usually 1.0)\n",
    "        \n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "\n",
    "    def visualize_labeled_pcd(self):\n",
    "        \"\"\"\n",
    "        Show the final color-coded point cloud after labeling (stem vs leaf).\n",
    "        \"\"\"\n",
    "        if self.labeled_pcd is None:\n",
    "            print(\"[WARN] No labeled_pcd => run_full_pipeline first.\")\n",
    "            return\n",
    "        o3d.visualization.draw_geometries([self.labeled_pcd], window_name=\"Stem vs Leaf Labeled PC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Gladius_B6_2023-06-27-2029_fused_output_cluster_0.ply\"\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Alsen_F9_2023-06-30-2109_fused_output_cluster_6.ply\"\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Brandon_C0_2023-06-28-1220_fused_output_cluster_5.ply\"\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Brandon_C0_2023-06-28-1220_fused_output_cluster_6.ply\"\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Chara_A0_2023-06-27-1536_fused_output_cluster_0.ply\"\n",
    "\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Chara_A1_2023-06-27-1507_fused_output_cluster_1.ply\"\n",
    "\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Chara_A8_2023-06-27-1724_fused_output_cluster_10.ply\"\n",
    "\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\"\n",
    "#filename = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Gladius_B0_2023-06-27-2226_fused_output_cluster_1.ply\"\n",
    "\n",
    "\n",
    "#input_path= r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Brandon_C0_2023-06-28-1220_fused_output_cluster_5.ply\"\n",
    "\n",
    "\n",
    "\n",
    "####################################### Test #########################################################\n",
    "\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\processed_single\\Wheat_Brandon_C1_2023-06-28-1139_fused_output_cluster_1.ply\"\n",
    "\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\"\n",
    "\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\adjustments\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\adjustments_Gladius\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg_2\\Wheat_Teal_E0_2023-06-30-1636_fused_output_cluster_3.ply\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\adjustments_Gladius\\Wheat_Gladius_B2_2023-06-27-0014_fused_output_cluster_9.ply\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_dense_seg\"\n",
    "\n",
    "\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Kukri_D3_2023-06-28-1928_fused_output_cluster_1.ply\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Kukri_D5_2023-06-28-1809_fused_output_cluster_0.ply\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_dense_seg\\Wheat_Chara_A3_2023-06-27-1356_fused_output_cluster_2.ply\"\n",
    "\n",
    "\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\processed_single\\Wheat_Chara_A4_2023-06-27-1810_fused_output_cluster_4.ply\"\n",
    "\n",
    "input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\processed_single\\Wheat_Gladius_B6_2023-06-27-2029_fused_output_cluster_0.ply\"\n",
    "#input_path = r\"C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\test_folder_mainstem_seg\\Wheat_Kukri_D6_2023-06-28-1741_fused_output_cluster_0.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded point cloud: C:\\Users\\joe_h\\Desktop\\work_projects\\PhotoPi\\photopack\\point_cloud_analysis\\point_cloud_data\\processed_single\\Wheat_Gladius_B6_2023-06-27-2029_fused_output_cluster_0.ply\n",
      "[DEBUG] trunk_axis = [-0.38239125  0.06982155  0.92135871]\n",
      "[_bridge_subgraphs_full_increasing_debug] bridging_dist= 0.050\n",
      "[_bridge_subgraphs_full_debug] pass=0\n",
      "[_find_subgraphs_debug] total nodes in adjacency= 62\n",
      " => BFS start node= (0, 0)\n",
      " => subgraph found => size= 23\n",
      " => BFS start node= (9, 0)\n",
      " => subgraph found => size= 15\n",
      " => BFS start node= (19, 0)\n",
      " => subgraph found => size= 27\n",
      " => total subgraphs= 3\n",
      "[_bridge_subgraphs_once_debug] Found 3 subgraphs => bridgingDist=0.050\n",
      "[_bridge_subgraphs_once_debug] bridging subgraph 0 & 1 via nodes (8, 0)--(9, 0), dist=0.024\n",
      " => Also adding vertical adjacency (8, 0) -> (9, 0)\n",
      "[_bridge_subgraphs_once_debug] bridging subgraph 0 & 2 via nodes (18, 1)--(19, 0), dist=0.027\n",
      " => Also adding vertical adjacency (18, 1) -> (19, 0)\n",
      "[_bridge_subgraphs_full_debug] pass=0 => now fully connected.\n",
      "[_bridge_subgraphs_full_increasing_debug] => single subgraph at dist=0.050\n",
      "[A] bridging => final bridging_dist= 0.050, subg= 1\n",
      "[DEBUG] build_raindrop_negcost_digraph => #edges= 64\n",
      "[DEBUG] branch points detected: 2\n",
      "[DEBUG] Longest path has 46 nodes and 2 branch points\n",
      "[A] trunk => base=0, top=64, cost=-40.431\n",
      "[_bridge_subgraphs_full_increasing_debug] bridging_dist= 0.050\n",
      "[_bridge_subgraphs_full_debug] pass=0\n",
      "[_find_subgraphs_debug] total nodes in adjacency= 62\n",
      " => BFS start node= (0, 0)\n",
      " => subgraph found => size= 46\n",
      " => BFS start node= (9, 1)\n",
      " => subgraph found => size= 14\n",
      " => BFS start node= (19, 1)\n",
      " => subgraph found => size= 5\n",
      " => total subgraphs= 3\n",
      "[_bridge_subgraphs_once_debug] Found 3 subgraphs => bridgingDist=0.050\n",
      "[_bridge_subgraphs_once_debug] bridging subgraph 0 & 2 via nodes (18, 1)--(19, 1), dist=0.022\n",
      " => Also adding vertical adjacency (18, 1) -> (19, 1)\n",
      "[_bridge_subgraphs_once_debug] bridging subgraph 0 & 1 via nodes (8, 0)--(9, 1), dist=0.022\n",
      " => Also adding vertical adjacency (8, 0) -> (9, 1)\n",
      "[_bridge_subgraphs_full_debug] pass=0 => now fully connected.\n",
      "[_bridge_subgraphs_full_increasing_debug] => single subgraph at dist=0.050\n",
      "[B] bridging => final bridging_dist= 0.050, subg= 1\n",
      "[DEBUG] build_raindrop_negcost_digraph => #edges= 64\n",
      "[DEBUG] branch points detected: 2\n",
      "[DEBUG] Longest path has 46 nodes and 2 branch points\n",
      "[B] trunk => base=0, top=64, cost=-40.431\n",
      "[MASTER] chosen adjacency= B, trunk_cost= -40.431\n",
      "[DEBUG] => now refine outlier branch_off, if any.\n",
      "[INFO] Created labeled PCD => #points= 23733\n",
      "[END OF PIPELINE] => main stem & branch_off labeled => done.\n",
      "[mainstem_segmentation] Pipeline complete => trunk path extracted, labeled PCD available.\n",
      "[NODE-BFS ANGLE] b_off=8, angle=21.19°, z=0.64\n",
      "[NODE-BFS ANGLE] b_off=28, angle=15.86°, z=0.84\n",
      "[MAIN ANGLE] branch=1, angle=15.86°, z=0.84\n",
      "[INFO] branch 0 => BFS-based angle= 21.19 deg\n",
      "[INFO] branch 1 => BFS-based angle= 15.86 deg\n",
      "Leaf_angle_0: 21.190010509469158\n",
      "Leaf_angle_1: 15.861340126644267\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "if os.path.isfile(input_path):\n",
    "    if not input_path.lower().endswith('.ply'):\n",
    "        print(f\"Input file is not .ply: {input_path}\")\n",
    "    ply_files = [input_path]\n",
    "elif os.path.isdir(input_path):\n",
    "    ply_files = glob.glob(os.path.join(input_path, '*.ply'))\n",
    "    if not ply_files:\n",
    "        print(f\"No .ply found in {input_path}\")\n",
    "else:\n",
    "    print(f\"Invalid path: {input_path}\")\n",
    "\n",
    "def load_point_cloud(filename):\n",
    "    \"\"\"\n",
    "    Load a .ply with Open3D.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(filename)\n",
    "        if not pcd.has_points():\n",
    "            print(f\"No points found: {filename}\")\n",
    "        print(f\"Loaded point cloud: {filename}\")\n",
    "        return pcd\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading point cloud: {e}\")\n",
    "\n",
    "\n",
    "for ply_file in ply_files:\n",
    "    point_cloud = load_point_cloud(ply_file)\n",
    "    # 1) Initialize the segmentation class with the point cloud.\n",
    "    segmentation = MainStemSegmentation(point_cloud)\n",
    "\n",
    "    # 2) Run the entire pipeline in one shot:\n",
    "    segmentation.run_full_pipeline(\n",
    "        alpha=1.0,\n",
    "        beta=2.0,\n",
    "        raindrop_alpha=1.0,\n",
    "        raindrop_beta=1.0,\n",
    "        gamma=1.0,\n",
    "        delta=5.0,\n",
    "        use_trunk_axis=True,\n",
    "        debug=True\n",
    "    )\n",
    "\n",
    "    # segmentation.run_full_pipeline(\n",
    "    #     alpha=1.0,\n",
    "    #     beta=0.5,\n",
    "    #     raindrop_alpha=0.5,\n",
    "    #     raindrop_beta=1.0,\n",
    "    #     gamma=5.0,\n",
    "    #     delta=30.0,\n",
    "    #     use_trunk_axis=True,\n",
    "    #     debug=True\n",
    "    # )\n",
    "\n",
    "    segmentation.visualize_final_graph_types()\n",
    "    #segmentation.visualize_final_graph_types_matplotlib()\n",
    "    print(\"[mainstem_segmentation] Pipeline complete => trunk path extracted, labeled PCD available.\")\n",
    "\n",
    "    # The pipeline produces trunk_path, labeled_pcd, branch_off_nodes, etc.\n",
    "    # If you want to visualize the final labeled point cloud:\n",
    "    if segmentation.labeled_pcd is not None:\n",
    "        o3d.visualization.draw_geometries(\n",
    "            [segmentation.labeled_pcd],\n",
    "            window_name=\"MainStemSegmentation - Labeled PCD\"\n",
    "        )\n",
    "\n",
    "\n",
    "    la = LeafAngleAnalyzer(segmentation)\n",
    "    la.compute_leaf_angles_node_bfs(\n",
    "        n_main_stem=5,\n",
    "        n_leaf=5,\n",
    "        min_leaf_for_angle=4,\n",
    "        max_bfs_depth=5\n",
    "        )\n",
    "    la.visualize_leaf_angles()\n",
    "\n",
    "\n",
    "    valid_angles = [ang for ang in la.angles if ang is not None]\n",
    "\n",
    "    for i in range(len(valid_angles)):\n",
    "        print(f\"Leaf_angle_{i}: {valid_angles[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
